From afdd31a1a755560ec6e1801e99b700560a45870b Mon Sep 17 00:00:00 2001
From: Julius Koskela <me@juliuskoskela.dev>
Date: Wed, 21 Jun 2023 23:17:04 +0300
Subject: virtio-wayland-tegra

---
 drivers/Kconfig            |    4 +
 drivers/Makefile           |    8 +
 drivers/virtio/internal.h  |  244 +++++++
 drivers/virtio/syscalls.h  | 1401 ++++++++++++++++++++++++++++++++++++
 drivers/virtio/virtio_wl.c | 1387 +++++++++++++++++++++++++++++++++++
 drivers/virtio/virtio_wl.h |  154 ++++
 drivers/virtio/virtwl.h    |   69 ++
 7 files changed, 3267 insertions(+)
 create mode 100644 drivers/virtio/internal.h
 create mode 100644 drivers/virtio/syscalls.h
 create mode 100644 drivers/virtio/virtio_wl.c
 create mode 100644 drivers/virtio/virtio_wl.h
 create mode 100644 drivers/virtio/virtwl.h

diff --git a/drivers/Kconfig b/drivers/Kconfig
index dcecc9f6e33f..12eb3554801c 100644
--- a/drivers/Kconfig
+++ b/drivers/Kconfig
@@ -236,3 +236,7 @@ source "drivers/counter/Kconfig"
 
 source "drivers/most/Kconfig"
 endmenu
+config VIRTIO_WAYLAND
+	bool "VirtIO wayland driver"
+	help
+	  VirtIO wayland driver ported from ChromeOS kernel to mainline
\ No newline at end of file
diff --git a/drivers/Makefile b/drivers/Makefile
index d3500440b928..825848292171 100644
--- a/drivers/Makefile
+++ b/drivers/Makefile
@@ -191,3 +191,11 @@ obj-$(CONFIG_GNSS)		+= gnss/
 obj-$(CONFIG_INTERCONNECT)	+= interconnect/
 obj-$(CONFIG_COUNTER)		+= counter/
 obj-$(CONFIG_MOST)		+= most/
+obj-m += virtio_wl.o
+
+all:
+	make -C /lib/modules/$(shell uname -r)/build M=$(PWD) modules
+
+clean:
+	make -C /lib/modules/$(shell uname -r)/build M=$(PWD) clean
+
diff --git a/drivers/virtio/internal.h b/drivers/virtio/internal.h
new file mode 100644
index 000000000000..5545c26d86ae
--- /dev/null
+++ b/drivers/virtio/internal.h
@@ -0,0 +1,244 @@
+/* SPDX-License-Identifier: GPL-2.0-or-later */
+/* fs/ internal definitions
+ *
+ * Copyright (C) 2006 Red Hat, Inc. All Rights Reserved.
+ * Written by David Howells (dhowells@redhat.com)
+ */
+
+struct super_block;
+struct file_system_type;
+struct iomap;
+struct iomap_ops;
+struct linux_binprm;
+struct path;
+struct mount;
+struct shrink_control;
+struct fs_context;
+struct user_namespace;
+struct pipe_inode_info;
+struct iov_iter;
+
+/*
+ * block/bdev.c
+ */
+#ifdef CONFIG_BLOCK
+extern void __init bdev_cache_init(void);
+
+void emergency_thaw_bdev(struct super_block *sb);
+#else
+static inline void bdev_cache_init(void)
+{
+}
+static inline int emergency_thaw_bdev(struct super_block *sb)
+{
+	return 0;
+}
+#endif /* CONFIG_BLOCK */
+
+/*
+ * buffer.c
+ */
+int __block_write_begin_int(struct folio *folio, loff_t pos, unsigned len,
+		get_block_t *get_block, const struct iomap *iomap);
+
+/*
+ * char_dev.c
+ */
+extern void __init chrdev_init(void);
+
+/*
+ * fs_context.c
+ */
+extern const struct fs_context_operations legacy_fs_context_ops;
+extern int parse_monolithic_mount_data(struct fs_context *, void *);
+extern void vfs_clean_context(struct fs_context *fc);
+extern int finish_clean_context(struct fs_context *fc);
+
+/*
+ * namei.c
+ */
+extern int filename_lookup(int dfd, struct filename *name, unsigned flags,
+			   struct path *path, struct path *root);
+extern int vfs_path_lookup(struct dentry *, struct vfsmount *,
+			   const char *, unsigned int, struct path *);
+int do_rmdir(int dfd, struct filename *name);
+int do_unlinkat(int dfd, struct filename *name);
+int may_linkat(struct user_namespace *mnt_userns, const struct path *link);
+int do_renameat2(int olddfd, struct filename *oldname, int newdfd,
+		 struct filename *newname, unsigned int flags);
+int do_mkdirat(int dfd, struct filename *name, umode_t mode);
+int do_symlinkat(struct filename *from, int newdfd, struct filename *to);
+int do_linkat(int olddfd, struct filename *old, int newdfd,
+			struct filename *new, int flags);
+
+/*
+ * namespace.c
+ */
+extern struct vfsmount *lookup_mnt(const struct path *);
+extern int finish_automount(struct vfsmount *, const struct path *);
+
+extern int sb_prepare_remount_readonly(struct super_block *);
+
+extern void __init mnt_init(void);
+
+extern int __mnt_want_write_file(struct file *);
+extern void __mnt_drop_write_file(struct file *);
+
+extern void dissolve_on_fput(struct vfsmount *);
+extern bool may_mount(void);
+
+int path_mount(const char *dev_name, struct path *path,
+		const char *type_page, unsigned long flags, void *data_page);
+int path_umount(struct path *path, int flags);
+
+/*
+ * fs_struct.c
+ */
+extern void chroot_fs_refs(const struct path *, const struct path *);
+
+/*
+ * file_table.c
+ */
+extern struct file *alloc_empty_file(int, const struct cred *);
+extern struct file *alloc_empty_file_noaccount(int, const struct cred *);
+
+static inline void put_file_access(struct file *file)
+{
+	if ((file->f_mode & (FMODE_READ | FMODE_WRITE)) == FMODE_READ) {
+		i_readcount_dec(file->f_inode);
+	} else if (file->f_mode & FMODE_WRITER) {
+		put_write_access(file->f_inode);
+		__mnt_drop_write(file->f_path.mnt);
+	}
+}
+
+/*
+ * super.c
+ */
+extern int reconfigure_super(struct fs_context *);
+extern bool trylock_super(struct super_block *sb);
+struct super_block *user_get_super(dev_t, bool excl);
+void put_super(struct super_block *sb);
+extern bool mount_capable(struct fs_context *);
+
+/*
+ * open.c
+ */
+struct open_flags {
+	int open_flag;
+	umode_t mode;
+	int acc_mode;
+	int intent;
+	int lookup_flags;
+};
+extern struct file *do_filp_open(int dfd, struct filename *pathname,
+		const struct open_flags *op);
+extern struct file *do_file_open_root(const struct path *,
+		const char *, const struct open_flags *);
+extern struct open_how build_open_how(int flags, umode_t mode);
+extern int build_open_flags(const struct open_how *how, struct open_flags *op);
+extern struct file *__close_fd_get_file(unsigned int fd);
+
+long do_sys_ftruncate(unsigned int fd, loff_t length, int small);
+int chmod_common(const struct path *path, umode_t mode);
+int do_fchownat(int dfd, const char __user *filename, uid_t user, gid_t group,
+		int flag);
+int chown_common(const struct path *path, uid_t user, gid_t group);
+extern int vfs_open(const struct path *, struct file *);
+
+/*
+ * inode.c
+ */
+extern long prune_icache_sb(struct super_block *sb, struct shrink_control *sc);
+int dentry_needs_remove_privs(struct user_namespace *, struct dentry *dentry);
+bool in_group_or_capable(struct user_namespace *mnt_userns,
+			 const struct inode *inode, vfsgid_t vfsgid);
+
+/*
+ * fs-writeback.c
+ */
+extern long get_nr_dirty_inodes(void);
+extern int invalidate_inodes(struct super_block *, bool);
+
+/*
+ * dcache.c
+ */
+extern int d_set_mounted(struct dentry *dentry);
+extern long prune_dcache_sb(struct super_block *sb, struct shrink_control *sc);
+extern struct dentry *d_alloc_cursor(struct dentry *);
+extern struct dentry * d_alloc_pseudo(struct super_block *, const struct qstr *);
+extern char *simple_dname(struct dentry *, char *, int);
+extern void dput_to_list(struct dentry *, struct list_head *);
+extern void shrink_dentry_list(struct list_head *);
+
+/*
+ * pipe.c
+ */
+extern const struct file_operations pipefifo_fops;
+
+/*
+ * fs_pin.c
+ */
+extern void group_pin_kill(struct hlist_head *p);
+extern void mnt_pin_kill(struct mount *m);
+
+/*
+ * fs/nsfs.c
+ */
+extern const struct dentry_operations ns_dentry_operations;
+
+/* direct-io.c: */
+int sb_init_dio_done_wq(struct super_block *sb);
+
+/*
+ * fs/stat.c:
+ */
+
+int getname_statx_lookup_flags(int flags);
+int do_statx(int dfd, struct filename *filename, unsigned int flags,
+	     unsigned int mask, struct statx __user *buffer);
+
+/*
+ * fs/splice.c:
+ */
+long splice_file_to_pipe(struct file *in,
+			 struct pipe_inode_info *opipe,
+			 loff_t *offset,
+			 size_t len, unsigned int flags);
+
+/*
+ * fs/xattr.c:
+ */
+struct xattr_name {
+	char name[XATTR_NAME_MAX + 1];
+};
+
+struct xattr_ctx {
+	/* Value of attribute */
+	union {
+		const void __user *cvalue;
+		void __user *value;
+	};
+	void *kvalue;
+	size_t size;
+	/* Attribute name */
+	struct xattr_name *kname;
+	unsigned int flags;
+};
+
+
+ssize_t do_getxattr(struct user_namespace *mnt_userns,
+		    struct dentry *d,
+		    struct xattr_ctx *ctx);
+
+int setxattr_copy(const char __user *name, struct xattr_ctx *ctx);
+int do_setxattr(struct user_namespace *mnt_userns, struct dentry *dentry,
+		struct xattr_ctx *ctx);
+
+ssize_t __kernel_write_iter(struct file *file, struct iov_iter *from, loff_t *pos);
+
+/*
+ * fs/attr.c
+ */
+int setattr_should_drop_sgid(struct user_namespace *mnt_userns,
+			     const struct inode *inode);
diff --git a/drivers/virtio/syscalls.h b/drivers/virtio/syscalls.h
new file mode 100644
index 000000000000..4a37f98e2d6d
--- /dev/null
+++ b/drivers/virtio/syscalls.h
@@ -0,0 +1,1401 @@
+/* SPDX-License-Identifier: GPL-2.0-only */
+/*
+ * syscalls.h - Linux syscall interfaces (non-arch-specific)
+ *
+ * Copyright (c) 2004 Randy Dunlap
+ * Copyright (c) 2004 Open Source Development Labs
+ */
+
+#ifndef _LINUX_SYSCALLS_H
+#define _LINUX_SYSCALLS_H
+
+struct __aio_sigset;
+struct epoll_event;
+struct iattr;
+struct inode;
+struct iocb;
+struct io_event;
+struct iovec;
+struct __kernel_old_itimerval;
+struct kexec_segment;
+struct linux_dirent;
+struct linux_dirent64;
+struct list_head;
+struct mmap_arg_struct;
+struct msgbuf;
+struct user_msghdr;
+struct mmsghdr;
+struct msqid_ds;
+struct new_utsname;
+struct nfsctl_arg;
+struct __old_kernel_stat;
+struct oldold_utsname;
+struct old_utsname;
+struct pollfd;
+struct rlimit;
+struct rlimit64;
+struct rusage;
+struct sched_param;
+struct sched_attr;
+struct sel_arg_struct;
+struct semaphore;
+struct sembuf;
+struct shmid_ds;
+struct sockaddr;
+struct stat;
+struct stat64;
+struct statfs;
+struct statfs64;
+struct statx;
+struct sysinfo;
+struct timespec;
+struct __kernel_old_timeval;
+struct __kernel_timex;
+struct timezone;
+struct tms;
+struct utimbuf;
+struct mq_attr;
+struct compat_stat;
+struct old_timeval32;
+struct robust_list_head;
+struct getcpu_cache;
+struct old_linux_dirent;
+struct perf_event_attr;
+struct file_handle;
+struct sigaltstack;
+struct rseq;
+union bpf_attr;
+struct io_uring_params;
+struct clone_args;
+struct open_how;
+struct landlock_ruleset_attr;
+enum landlock_rule_type;
+
+#include <linux/types.h>
+#include <linux/aio_abi.h>
+#include <linux/capability.h>
+#include <linux/signal.h>
+#include <linux/list.h>
+#include <linux/bug.h>
+#include <linux/sem.h>
+#include <asm/siginfo.h>
+#include <linux/unistd.h>
+#include <linux/quota.h>
+#include <linux/key.h>
+#include <linux/personality.h>
+#include <trace/syscall.h>
+
+#ifdef CONFIG_ARCH_HAS_SYSCALL_WRAPPER
+/*
+ * It may be useful for an architecture to override the definitions of the
+ * SYSCALL_DEFINE0() and __SYSCALL_DEFINEx() macros, in particular to use a
+ * different calling convention for syscalls. To allow for that, the prototypes
+ * for the sys_*() functions below will *not* be included if
+ * CONFIG_ARCH_HAS_SYSCALL_WRAPPER is enabled.
+ */
+#include <asm/syscall_wrapper.h>
+#endif /* CONFIG_ARCH_HAS_SYSCALL_WRAPPER */
+
+/*
+ * __MAP - apply a macro to syscall arguments
+ * __MAP(n, m, t1, a1, t2, a2, ..., tn, an) will expand to
+ *    m(t1, a1), m(t2, a2), ..., m(tn, an)
+ * The first argument must be equal to the amount of type/name
+ * pairs given.  Note that this list of pairs (i.e. the arguments
+ * of __MAP starting at the third one) is in the same format as
+ * for SYSCALL_DEFINE<n>/COMPAT_SYSCALL_DEFINE<n>
+ */
+#define __MAP0(m,...)
+#define __MAP1(m,t,a,...) m(t,a)
+#define __MAP2(m,t,a,...) m(t,a), __MAP1(m,__VA_ARGS__)
+#define __MAP3(m,t,a,...) m(t,a), __MAP2(m,__VA_ARGS__)
+#define __MAP4(m,t,a,...) m(t,a), __MAP3(m,__VA_ARGS__)
+#define __MAP5(m,t,a,...) m(t,a), __MAP4(m,__VA_ARGS__)
+#define __MAP6(m,t,a,...) m(t,a), __MAP5(m,__VA_ARGS__)
+#define __MAP(n,...) __MAP##n(__VA_ARGS__)
+
+#define __SC_DECL(t, a)	t a
+#define __TYPE_AS(t, v)	__same_type((__force t)0, v)
+#define __TYPE_IS_L(t)	(__TYPE_AS(t, 0L))
+#define __TYPE_IS_UL(t)	(__TYPE_AS(t, 0UL))
+#define __TYPE_IS_LL(t) (__TYPE_AS(t, 0LL) || __TYPE_AS(t, 0ULL))
+#define __SC_LONG(t, a) __typeof(__builtin_choose_expr(__TYPE_IS_LL(t), 0LL, 0L)) a
+#define __SC_CAST(t, a)	(__force t) a
+#define __SC_ARGS(t, a)	a
+#define __SC_TEST(t, a) (void)BUILD_BUG_ON_ZERO(!__TYPE_IS_LL(t) && sizeof(t) > sizeof(long))
+
+#ifdef CONFIG_FTRACE_SYSCALLS
+#define __SC_STR_ADECL(t, a)	#a
+#define __SC_STR_TDECL(t, a)	#t
+
+extern struct trace_event_class event_class_syscall_enter;
+extern struct trace_event_class event_class_syscall_exit;
+extern struct trace_event_functions enter_syscall_print_funcs;
+extern struct trace_event_functions exit_syscall_print_funcs;
+
+#define SYSCALL_TRACE_ENTER_EVENT(sname)				\
+	static struct syscall_metadata __syscall_meta_##sname;		\
+	static struct trace_event_call __used				\
+	  event_enter_##sname = {					\
+		.class			= &event_class_syscall_enter,	\
+		{							\
+			.name                   = "sys_enter"#sname,	\
+		},							\
+		.event.funcs            = &enter_syscall_print_funcs,	\
+		.data			= (void *)&__syscall_meta_##sname,\
+		.flags                  = TRACE_EVENT_FL_CAP_ANY,	\
+	};								\
+	static struct trace_event_call __used				\
+	  __section("_ftrace_events")					\
+	 *__event_enter_##sname = &event_enter_##sname;
+
+#define SYSCALL_TRACE_EXIT_EVENT(sname)					\
+	static struct syscall_metadata __syscall_meta_##sname;		\
+	static struct trace_event_call __used				\
+	  event_exit_##sname = {					\
+		.class			= &event_class_syscall_exit,	\
+		{							\
+			.name                   = "sys_exit"#sname,	\
+		},							\
+		.event.funcs		= &exit_syscall_print_funcs,	\
+		.data			= (void *)&__syscall_meta_##sname,\
+		.flags                  = TRACE_EVENT_FL_CAP_ANY,	\
+	};								\
+	static struct trace_event_call __used				\
+	  __section("_ftrace_events")					\
+	*__event_exit_##sname = &event_exit_##sname;
+
+#define SYSCALL_METADATA(sname, nb, ...)			\
+	static const char *types_##sname[] = {			\
+		__MAP(nb,__SC_STR_TDECL,__VA_ARGS__)		\
+	};							\
+	static const char *args_##sname[] = {			\
+		__MAP(nb,__SC_STR_ADECL,__VA_ARGS__)		\
+	};							\
+	SYSCALL_TRACE_ENTER_EVENT(sname);			\
+	SYSCALL_TRACE_EXIT_EVENT(sname);			\
+	static struct syscall_metadata __used			\
+	  __syscall_meta_##sname = {				\
+		.name 		= "sys"#sname,			\
+		.syscall_nr	= -1,	/* Filled in at boot */	\
+		.nb_args 	= nb,				\
+		.types		= nb ? types_##sname : NULL,	\
+		.args		= nb ? args_##sname : NULL,	\
+		.enter_event	= &event_enter_##sname,		\
+		.exit_event	= &event_exit_##sname,		\
+		.enter_fields	= LIST_HEAD_INIT(__syscall_meta_##sname.enter_fields), \
+	};							\
+	static struct syscall_metadata __used			\
+	  __section("__syscalls_metadata")			\
+	 *__p_syscall_meta_##sname = &__syscall_meta_##sname;
+
+static inline int is_syscall_trace_event(struct trace_event_call *tp_event)
+{
+	return tp_event->class == &event_class_syscall_enter ||
+	       tp_event->class == &event_class_syscall_exit;
+}
+
+#else
+#define SYSCALL_METADATA(sname, nb, ...)
+
+static inline int is_syscall_trace_event(struct trace_event_call *tp_event)
+{
+	return 0;
+}
+#endif
+
+#ifndef SYSCALL_DEFINE0
+#define SYSCALL_DEFINE0(sname)					\
+	SYSCALL_METADATA(_##sname, 0);				\
+	asmlinkage long sys_##sname(void);			\
+	ALLOW_ERROR_INJECTION(sys_##sname, ERRNO);		\
+	asmlinkage long sys_##sname(void)
+#endif /* SYSCALL_DEFINE0 */
+
+#define SYSCALL_DEFINE1(name, ...) SYSCALL_DEFINEx(1, _##name, __VA_ARGS__)
+#define SYSCALL_DEFINE2(name, ...) SYSCALL_DEFINEx(2, _##name, __VA_ARGS__)
+#define SYSCALL_DEFINE3(name, ...) SYSCALL_DEFINEx(3, _##name, __VA_ARGS__)
+#define SYSCALL_DEFINE4(name, ...) SYSCALL_DEFINEx(4, _##name, __VA_ARGS__)
+#define SYSCALL_DEFINE5(name, ...) SYSCALL_DEFINEx(5, _##name, __VA_ARGS__)
+#define SYSCALL_DEFINE6(name, ...) SYSCALL_DEFINEx(6, _##name, __VA_ARGS__)
+
+#define SYSCALL_DEFINE_MAXARGS	6
+
+#define SYSCALL_DEFINEx(x, sname, ...)				\
+	SYSCALL_METADATA(sname, x, __VA_ARGS__)			\
+	__SYSCALL_DEFINEx(x, sname, __VA_ARGS__)
+
+#define __PROTECT(...) asmlinkage_protect(__VA_ARGS__)
+
+/*
+ * The asmlinkage stub is aliased to a function named __se_sys_*() which
+ * sign-extends 32-bit ints to longs whenever needed. The actual work is
+ * done within __do_sys_*().
+ */
+#ifndef __SYSCALL_DEFINEx
+#define __SYSCALL_DEFINEx(x, name, ...)					\
+	__diag_push();							\
+	__diag_ignore(GCC, 8, "-Wattribute-alias",			\
+		      "Type aliasing is used to sanitize syscall arguments");\
+	asmlinkage long sys##name(__MAP(x,__SC_DECL,__VA_ARGS__))	\
+		__attribute__((alias(__stringify(__se_sys##name))));	\
+	ALLOW_ERROR_INJECTION(sys##name, ERRNO);			\
+	static inline long __do_sys##name(__MAP(x,__SC_DECL,__VA_ARGS__));\
+	asmlinkage long __se_sys##name(__MAP(x,__SC_LONG,__VA_ARGS__));	\
+	asmlinkage long __se_sys##name(__MAP(x,__SC_LONG,__VA_ARGS__))	\
+	{								\
+		long ret = __do_sys##name(__MAP(x,__SC_CAST,__VA_ARGS__));\
+		__MAP(x,__SC_TEST,__VA_ARGS__);				\
+		__PROTECT(x, ret,__MAP(x,__SC_ARGS,__VA_ARGS__));	\
+		return ret;						\
+	}								\
+	__diag_pop();							\
+	static inline long __do_sys##name(__MAP(x,__SC_DECL,__VA_ARGS__))
+#endif /* __SYSCALL_DEFINEx */
+
+/* For split 64-bit arguments on 32-bit architectures */
+#ifdef __LITTLE_ENDIAN
+#define SC_ARG64(name) u32, name##_lo, u32, name##_hi
+#else
+#define SC_ARG64(name) u32, name##_hi, u32, name##_lo
+#endif
+#define SC_VAL64(type, name) ((type) name##_hi << 32 | name##_lo)
+
+#ifdef CONFIG_COMPAT
+#define SYSCALL32_DEFINE1 COMPAT_SYSCALL_DEFINE1
+#define SYSCALL32_DEFINE2 COMPAT_SYSCALL_DEFINE2
+#define SYSCALL32_DEFINE3 COMPAT_SYSCALL_DEFINE3
+#define SYSCALL32_DEFINE4 COMPAT_SYSCALL_DEFINE4
+#define SYSCALL32_DEFINE5 COMPAT_SYSCALL_DEFINE5
+#define SYSCALL32_DEFINE6 COMPAT_SYSCALL_DEFINE6
+#else
+#define SYSCALL32_DEFINE1 SYSCALL_DEFINE1
+#define SYSCALL32_DEFINE2 SYSCALL_DEFINE2
+#define SYSCALL32_DEFINE3 SYSCALL_DEFINE3
+#define SYSCALL32_DEFINE4 SYSCALL_DEFINE4
+#define SYSCALL32_DEFINE5 SYSCALL_DEFINE5
+#define SYSCALL32_DEFINE6 SYSCALL_DEFINE6
+#endif
+
+/*
+ * Called before coming back to user-mode. Returning to user-mode with an
+ * address limit different than USER_DS can allow to overwrite kernel memory.
+ */
+static inline void addr_limit_user_check(void)
+{
+#ifdef TIF_FSCHECK
+	if (!test_thread_flag(TIF_FSCHECK))
+		return;
+#endif
+
+	if (CHECK_DATA_CORRUPTION(uaccess_kernel(),
+				  "Invalid address limit on user-mode return"))
+		force_sig(SIGKILL);
+
+#ifdef TIF_FSCHECK
+	clear_thread_flag(TIF_FSCHECK);
+#endif
+}
+
+/*
+ * These syscall function prototypes are kept in the same order as
+ * include/uapi/asm-generic/unistd.h. Architecture specific entries go below,
+ * followed by deprecated or obsolete system calls.
+ *
+ * Please note that these prototypes here are only provided for information
+ * purposes, for static analysis, and for linking from the syscall table.
+ * These functions should not be called elsewhere from kernel code.
+ *
+ * As the syscall calling convention may be different from the default
+ * for architectures overriding the syscall calling convention, do not
+ * include the prototypes if CONFIG_ARCH_HAS_SYSCALL_WRAPPER is enabled.
+ */
+#ifndef CONFIG_ARCH_HAS_SYSCALL_WRAPPER
+asmlinkage long sys_io_setup(unsigned nr_reqs, aio_context_t __user *ctx);
+asmlinkage long sys_io_destroy(aio_context_t ctx);
+asmlinkage long sys_io_submit(aio_context_t, long,
+			struct iocb __user * __user *);
+asmlinkage long sys_io_cancel(aio_context_t ctx_id, struct iocb __user *iocb,
+			      struct io_event __user *result);
+asmlinkage long sys_io_getevents(aio_context_t ctx_id,
+				long min_nr,
+				long nr,
+				struct io_event __user *events,
+				struct __kernel_timespec __user *timeout);
+asmlinkage long sys_io_getevents_time32(__u32 ctx_id,
+				__s32 min_nr,
+				__s32 nr,
+				struct io_event __user *events,
+				struct old_timespec32 __user *timeout);
+asmlinkage long sys_io_pgetevents(aio_context_t ctx_id,
+				long min_nr,
+				long nr,
+				struct io_event __user *events,
+				struct __kernel_timespec __user *timeout,
+				const struct __aio_sigset *sig);
+asmlinkage long sys_io_pgetevents_time32(aio_context_t ctx_id,
+				long min_nr,
+				long nr,
+				struct io_event __user *events,
+				struct old_timespec32 __user *timeout,
+				const struct __aio_sigset *sig);
+asmlinkage long sys_io_uring_setup(u32 entries,
+				struct io_uring_params __user *p);
+asmlinkage long sys_io_uring_enter(unsigned int fd, u32 to_submit,
+				u32 min_complete, u32 flags,
+				const void __user *argp, size_t argsz);
+asmlinkage long sys_io_uring_register(unsigned int fd, unsigned int op,
+				void __user *arg, unsigned int nr_args);
+
+/* fs/xattr.c */
+asmlinkage long sys_setxattr(const char __user *path, const char __user *name,
+			     const void __user *value, size_t size, int flags);
+asmlinkage long sys_lsetxattr(const char __user *path, const char __user *name,
+			      const void __user *value, size_t size, int flags);
+asmlinkage long sys_fsetxattr(int fd, const char __user *name,
+			      const void __user *value, size_t size, int flags);
+asmlinkage long sys_getxattr(const char __user *path, const char __user *name,
+			     void __user *value, size_t size);
+asmlinkage long sys_lgetxattr(const char __user *path, const char __user *name,
+			      void __user *value, size_t size);
+asmlinkage long sys_fgetxattr(int fd, const char __user *name,
+			      void __user *value, size_t size);
+asmlinkage long sys_listxattr(const char __user *path, char __user *list,
+			      size_t size);
+asmlinkage long sys_llistxattr(const char __user *path, char __user *list,
+			       size_t size);
+asmlinkage long sys_flistxattr(int fd, char __user *list, size_t size);
+asmlinkage long sys_removexattr(const char __user *path,
+				const char __user *name);
+asmlinkage long sys_lremovexattr(const char __user *path,
+				 const char __user *name);
+asmlinkage long sys_fremovexattr(int fd, const char __user *name);
+
+/* fs/dcache.c */
+asmlinkage long sys_getcwd(char __user *buf, unsigned long size);
+
+/* fs/cookies.c */
+asmlinkage long sys_lookup_dcookie(u64 cookie64, char __user *buf, size_t len);
+
+/* fs/eventfd.c */
+asmlinkage long sys_eventfd2(unsigned int count, int flags);
+
+/* fs/eventpoll.c */
+asmlinkage long sys_epoll_create1(int flags);
+asmlinkage long sys_epoll_ctl(int epfd, int op, int fd,
+				struct epoll_event __user *event);
+asmlinkage long sys_epoll_pwait(int epfd, struct epoll_event __user *events,
+				int maxevents, int timeout,
+				const sigset_t __user *sigmask,
+				size_t sigsetsize);
+
+/* fs/fcntl.c */
+asmlinkage long sys_dup(unsigned int fildes);
+asmlinkage long sys_dup3(unsigned int oldfd, unsigned int newfd, int flags);
+asmlinkage long sys_fcntl(unsigned int fd, unsigned int cmd, unsigned long arg);
+#if BITS_PER_LONG == 32
+asmlinkage long sys_fcntl64(unsigned int fd,
+				unsigned int cmd, unsigned long arg);
+#endif
+
+/* fs/inotify_user.c */
+asmlinkage long sys_inotify_init1(int flags);
+asmlinkage long sys_inotify_add_watch(int fd, const char __user *path,
+					u32 mask);
+asmlinkage long sys_inotify_rm_watch(int fd, __s32 wd);
+
+/* fs/ioctl.c */
+asmlinkage long sys_ioctl(unsigned int fd, unsigned int cmd,
+				unsigned long arg);
+
+/* fs/ioprio.c */
+asmlinkage long sys_ioprio_set(int which, int who, int ioprio);
+asmlinkage long sys_ioprio_get(int which, int who);
+
+/* fs/locks.c */
+asmlinkage long sys_flock(unsigned int fd, unsigned int cmd);
+
+/* fs/namei.c */
+asmlinkage long sys_mknodat(int dfd, const char __user * filename, umode_t mode,
+			    unsigned dev);
+asmlinkage long sys_mkdirat(int dfd, const char __user * pathname, umode_t mode);
+asmlinkage long sys_unlinkat(int dfd, const char __user * pathname, int flag);
+asmlinkage long sys_symlinkat(const char __user * oldname,
+			      int newdfd, const char __user * newname);
+asmlinkage long sys_linkat(int olddfd, const char __user *oldname,
+			   int newdfd, const char __user *newname, int flags);
+asmlinkage long sys_renameat(int olddfd, const char __user * oldname,
+			     int newdfd, const char __user * newname);
+
+/* fs/namespace.c */
+asmlinkage long sys_umount(char __user *name, int flags);
+asmlinkage long sys_mount(char __user *dev_name, char __user *dir_name,
+				char __user *type, unsigned long flags,
+				void __user *data);
+asmlinkage long sys_pivot_root(const char __user *new_root,
+				const char __user *put_old);
+
+/* fs/nfsctl.c */
+
+/* fs/open.c */
+asmlinkage long sys_statfs(const char __user * path,
+				struct statfs __user *buf);
+asmlinkage long sys_statfs64(const char __user *path, size_t sz,
+				struct statfs64 __user *buf);
+asmlinkage long sys_fstatfs(unsigned int fd, struct statfs __user *buf);
+asmlinkage long sys_fstatfs64(unsigned int fd, size_t sz,
+				struct statfs64 __user *buf);
+asmlinkage long sys_truncate(const char __user *path, long length);
+asmlinkage long sys_ftruncate(unsigned int fd, unsigned long length);
+#if BITS_PER_LONG == 32
+asmlinkage long sys_truncate64(const char __user *path, loff_t length);
+asmlinkage long sys_ftruncate64(unsigned int fd, loff_t length);
+#endif
+asmlinkage long sys_fallocate(int fd, int mode, loff_t offset, loff_t len);
+asmlinkage long sys_faccessat(int dfd, const char __user *filename, int mode);
+asmlinkage long sys_faccessat2(int dfd, const char __user *filename, int mode,
+			       int flags);
+asmlinkage long sys_chdir(const char __user *filename);
+asmlinkage long sys_fchdir(unsigned int fd);
+asmlinkage long sys_chroot(const char __user *filename);
+asmlinkage long sys_fchmod(unsigned int fd, umode_t mode);
+asmlinkage long sys_fchmodat(int dfd, const char __user * filename,
+			     umode_t mode);
+asmlinkage long sys_fchownat(int dfd, const char __user *filename, uid_t user,
+			     gid_t group, int flag);
+asmlinkage long sys_fchown(unsigned int fd, uid_t user, gid_t group);
+asmlinkage long sys_openat(int dfd, const char __user *filename, int flags,
+			   umode_t mode);
+asmlinkage long sys_openat2(int dfd, const char __user *filename,
+			    struct open_how *how, size_t size);
+asmlinkage long sys_close(unsigned int fd);
+asmlinkage long sys_close_range(unsigned int fd, unsigned int max_fd,
+				unsigned int flags);
+asmlinkage long sys_vhangup(void);
+
+/* fs/pipe.c */
+asmlinkage long sys_pipe2(int __user *fildes, int flags);
+
+/* fs/quota.c */
+asmlinkage long sys_quotactl(unsigned int cmd, const char __user *special,
+				qid_t id, void __user *addr);
+
+/* fs/readdir.c */
+asmlinkage long sys_getdents64(unsigned int fd,
+				struct linux_dirent64 __user *dirent,
+				unsigned int count);
+
+/* fs/read_write.c */
+asmlinkage long sys_llseek(unsigned int fd, unsigned long offset_high,
+			unsigned long offset_low, loff_t __user *result,
+			unsigned int whence);
+asmlinkage long sys_lseek(unsigned int fd, off_t offset,
+			  unsigned int whence);
+asmlinkage long sys_read(unsigned int fd, char __user *buf, size_t count);
+asmlinkage long sys_write(unsigned int fd, const char __user *buf,
+			  size_t count);
+asmlinkage long sys_readv(unsigned long fd,
+			  const struct iovec __user *vec,
+			  unsigned long vlen);
+asmlinkage long sys_writev(unsigned long fd,
+			   const struct iovec __user *vec,
+			   unsigned long vlen);
+asmlinkage long sys_pread64(unsigned int fd, char __user *buf,
+			    size_t count, loff_t pos);
+asmlinkage long sys_pwrite64(unsigned int fd, const char __user *buf,
+			     size_t count, loff_t pos);
+asmlinkage long sys_preadv(unsigned long fd, const struct iovec __user *vec,
+			   unsigned long vlen, unsigned long pos_l, unsigned long pos_h);
+asmlinkage long sys_pwritev(unsigned long fd, const struct iovec __user *vec,
+			    unsigned long vlen, unsigned long pos_l, unsigned long pos_h);
+
+/* fs/sendfile.c */
+asmlinkage long sys_sendfile64(int out_fd, int in_fd,
+			       loff_t __user *offset, size_t count);
+
+/* fs/select.c */
+asmlinkage long sys_pselect6(int, fd_set __user *, fd_set __user *,
+			     fd_set __user *, struct __kernel_timespec __user *,
+			     void __user *);
+asmlinkage long sys_pselect6_time32(int, fd_set __user *, fd_set __user *,
+			     fd_set __user *, struct old_timespec32 __user *,
+			     void __user *);
+asmlinkage long sys_ppoll(struct pollfd __user *, unsigned int,
+			  struct __kernel_timespec __user *, const sigset_t __user *,
+			  size_t);
+asmlinkage long sys_ppoll_time32(struct pollfd __user *, unsigned int,
+			  struct old_timespec32 __user *, const sigset_t __user *,
+			  size_t);
+
+/* fs/signalfd.c */
+asmlinkage long sys_signalfd4(int ufd, sigset_t __user *user_mask, size_t sizemask, int flags);
+
+/* fs/splice.c */
+asmlinkage long sys_vmsplice(int fd, const struct iovec __user *iov,
+			     unsigned long nr_segs, unsigned int flags);
+asmlinkage long sys_splice(int fd_in, loff_t __user *off_in,
+			   int fd_out, loff_t __user *off_out,
+			   size_t len, unsigned int flags);
+asmlinkage long sys_tee(int fdin, int fdout, size_t len, unsigned int flags);
+
+/* fs/stat.c */
+asmlinkage long sys_readlinkat(int dfd, const char __user *path, char __user *buf,
+			       int bufsiz);
+asmlinkage long sys_newfstatat(int dfd, const char __user *filename,
+			       struct stat __user *statbuf, int flag);
+asmlinkage long sys_newfstat(unsigned int fd, struct stat __user *statbuf);
+#if defined(__ARCH_WANT_STAT64) || defined(__ARCH_WANT_COMPAT_STAT64)
+asmlinkage long sys_fstat64(unsigned long fd, struct stat64 __user *statbuf);
+asmlinkage long sys_fstatat64(int dfd, const char __user *filename,
+			       struct stat64 __user *statbuf, int flag);
+#endif
+
+/* fs/sync.c */
+asmlinkage long sys_sync(void);
+asmlinkage long sys_fsync(unsigned int fd);
+asmlinkage long sys_fdatasync(unsigned int fd);
+asmlinkage long sys_sync_file_range2(int fd, unsigned int flags,
+				     loff_t offset, loff_t nbytes);
+asmlinkage long sys_sync_file_range(int fd, loff_t offset, loff_t nbytes,
+					unsigned int flags);
+
+/* fs/timerfd.c */
+asmlinkage long sys_timerfd_create(int clockid, int flags);
+asmlinkage long sys_timerfd_settime(int ufd, int flags,
+				    const struct __kernel_itimerspec __user *utmr,
+				    struct __kernel_itimerspec __user *otmr);
+asmlinkage long sys_timerfd_gettime(int ufd, struct __kernel_itimerspec __user *otmr);
+asmlinkage long sys_timerfd_gettime32(int ufd,
+				   struct old_itimerspec32 __user *otmr);
+asmlinkage long sys_timerfd_settime32(int ufd, int flags,
+				   const struct old_itimerspec32 __user *utmr,
+				   struct old_itimerspec32 __user *otmr);
+
+/* fs/utimes.c */
+asmlinkage long sys_utimensat(int dfd, const char __user *filename,
+				struct __kernel_timespec __user *utimes,
+				int flags);
+asmlinkage long sys_utimensat_time32(unsigned int dfd,
+				const char __user *filename,
+				struct old_timespec32 __user *t, int flags);
+
+/* kernel/acct.c */
+asmlinkage long sys_acct(const char __user *name);
+
+/* kernel/capability.c */
+asmlinkage long sys_capget(cap_user_header_t header,
+				cap_user_data_t dataptr);
+asmlinkage long sys_capset(cap_user_header_t header,
+				const cap_user_data_t data);
+
+/* kernel/exec_domain.c */
+asmlinkage long sys_personality(unsigned int personality);
+
+/* kernel/exit.c */
+asmlinkage long sys_exit(int error_code);
+asmlinkage long sys_exit_group(int error_code);
+asmlinkage long sys_waitid(int which, pid_t pid,
+			   struct siginfo __user *infop,
+			   int options, struct rusage __user *ru);
+
+/* kernel/fork.c */
+asmlinkage long sys_set_tid_address(int __user *tidptr);
+asmlinkage long sys_unshare(unsigned long unshare_flags);
+
+/* kernel/futex.c */
+asmlinkage long sys_futex(u32 __user *uaddr, int op, u32 val,
+			struct __kernel_timespec __user *utime, u32 __user *uaddr2,
+			u32 val3);
+asmlinkage long sys_futex_time32(u32 __user *uaddr, int op, u32 val,
+			struct old_timespec32 __user *utime, u32 __user *uaddr2,
+			u32 val3);
+asmlinkage long sys_get_robust_list(int pid,
+				    struct robust_list_head __user * __user *head_ptr,
+				    size_t __user *len_ptr);
+asmlinkage long sys_set_robust_list(struct robust_list_head __user *head,
+				    size_t len);
+
+/* kernel/hrtimer.c */
+asmlinkage long sys_nanosleep(struct __kernel_timespec __user *rqtp,
+			      struct __kernel_timespec __user *rmtp);
+asmlinkage long sys_nanosleep_time32(struct old_timespec32 __user *rqtp,
+				     struct old_timespec32 __user *rmtp);
+
+/* kernel/itimer.c */
+asmlinkage long sys_getitimer(int which, struct __kernel_old_itimerval __user *value);
+asmlinkage long sys_setitimer(int which,
+				struct __kernel_old_itimerval __user *value,
+				struct __kernel_old_itimerval __user *ovalue);
+
+/* kernel/kexec.c */
+asmlinkage long sys_kexec_load(unsigned long entry, unsigned long nr_segments,
+				struct kexec_segment __user *segments,
+				unsigned long flags);
+
+/* kernel/module.c */
+asmlinkage long sys_init_module(void __user *umod, unsigned long len,
+				const char __user *uargs);
+asmlinkage long sys_delete_module(const char __user *name_user,
+				unsigned int flags);
+
+/* kernel/posix-timers.c */
+asmlinkage long sys_timer_create(clockid_t which_clock,
+				 struct sigevent __user *timer_event_spec,
+				 timer_t __user * created_timer_id);
+asmlinkage long sys_timer_gettime(timer_t timer_id,
+				struct __kernel_itimerspec __user *setting);
+asmlinkage long sys_timer_getoverrun(timer_t timer_id);
+asmlinkage long sys_timer_settime(timer_t timer_id, int flags,
+				const struct __kernel_itimerspec __user *new_setting,
+				struct __kernel_itimerspec __user *old_setting);
+asmlinkage long sys_timer_delete(timer_t timer_id);
+asmlinkage long sys_clock_settime(clockid_t which_clock,
+				const struct __kernel_timespec __user *tp);
+asmlinkage long sys_clock_gettime(clockid_t which_clock,
+				struct __kernel_timespec __user *tp);
+asmlinkage long sys_clock_getres(clockid_t which_clock,
+				struct __kernel_timespec __user *tp);
+asmlinkage long sys_clock_nanosleep(clockid_t which_clock, int flags,
+				const struct __kernel_timespec __user *rqtp,
+				struct __kernel_timespec __user *rmtp);
+asmlinkage long sys_timer_gettime32(timer_t timer_id,
+				 struct old_itimerspec32 __user *setting);
+asmlinkage long sys_timer_settime32(timer_t timer_id, int flags,
+					 struct old_itimerspec32 __user *new,
+					 struct old_itimerspec32 __user *old);
+asmlinkage long sys_clock_settime32(clockid_t which_clock,
+				struct old_timespec32 __user *tp);
+asmlinkage long sys_clock_gettime32(clockid_t which_clock,
+				struct old_timespec32 __user *tp);
+asmlinkage long sys_clock_getres_time32(clockid_t which_clock,
+				struct old_timespec32 __user *tp);
+asmlinkage long sys_clock_nanosleep_time32(clockid_t which_clock, int flags,
+				struct old_timespec32 __user *rqtp,
+				struct old_timespec32 __user *rmtp);
+
+/* kernel/printk.c */
+asmlinkage long sys_syslog(int type, char __user *buf, int len);
+
+/* kernel/ptrace.c */
+asmlinkage long sys_ptrace(long request, long pid, unsigned long addr,
+			   unsigned long data);
+/* kernel/sched/core.c */
+
+asmlinkage long sys_sched_setparam(pid_t pid,
+					struct sched_param __user *param);
+asmlinkage long sys_sched_setscheduler(pid_t pid, int policy,
+					struct sched_param __user *param);
+asmlinkage long sys_sched_getscheduler(pid_t pid);
+asmlinkage long sys_sched_getparam(pid_t pid,
+					struct sched_param __user *param);
+asmlinkage long sys_sched_setaffinity(pid_t pid, unsigned int len,
+					unsigned long __user *user_mask_ptr);
+asmlinkage long sys_sched_getaffinity(pid_t pid, unsigned int len,
+					unsigned long __user *user_mask_ptr);
+asmlinkage long sys_sched_yield(void);
+asmlinkage long sys_sched_get_priority_max(int policy);
+asmlinkage long sys_sched_get_priority_min(int policy);
+asmlinkage long sys_sched_rr_get_interval(pid_t pid,
+				struct __kernel_timespec __user *interval);
+asmlinkage long sys_sched_rr_get_interval_time32(pid_t pid,
+						 struct old_timespec32 __user *interval);
+
+/* kernel/signal.c */
+asmlinkage long sys_restart_syscall(void);
+asmlinkage long sys_kill(pid_t pid, int sig);
+asmlinkage long sys_tkill(pid_t pid, int sig);
+asmlinkage long sys_tgkill(pid_t tgid, pid_t pid, int sig);
+asmlinkage long sys_sigaltstack(const struct sigaltstack __user *uss,
+				struct sigaltstack __user *uoss);
+asmlinkage long sys_rt_sigsuspend(sigset_t __user *unewset, size_t sigsetsize);
+#ifndef CONFIG_ODD_RT_SIGACTION
+asmlinkage long sys_rt_sigaction(int,
+				 const struct sigaction __user *,
+				 struct sigaction __user *,
+				 size_t);
+#endif
+asmlinkage long sys_rt_sigprocmask(int how, sigset_t __user *set,
+				sigset_t __user *oset, size_t sigsetsize);
+asmlinkage long sys_rt_sigpending(sigset_t __user *set, size_t sigsetsize);
+asmlinkage long sys_rt_sigtimedwait(const sigset_t __user *uthese,
+				siginfo_t __user *uinfo,
+				const struct __kernel_timespec __user *uts,
+				size_t sigsetsize);
+asmlinkage long sys_rt_sigtimedwait_time32(const sigset_t __user *uthese,
+				siginfo_t __user *uinfo,
+				const struct old_timespec32 __user *uts,
+				size_t sigsetsize);
+asmlinkage long sys_rt_sigqueueinfo(pid_t pid, int sig, siginfo_t __user *uinfo);
+
+/* kernel/sys.c */
+asmlinkage long sys_setpriority(int which, int who, int niceval);
+asmlinkage long sys_getpriority(int which, int who);
+asmlinkage long sys_reboot(int magic1, int magic2, unsigned int cmd,
+				void __user *arg);
+asmlinkage long sys_setregid(gid_t rgid, gid_t egid);
+asmlinkage long sys_setgid(gid_t gid);
+asmlinkage long sys_setreuid(uid_t ruid, uid_t euid);
+asmlinkage long sys_setuid(uid_t uid);
+asmlinkage long sys_setresuid(uid_t ruid, uid_t euid, uid_t suid);
+asmlinkage long sys_getresuid(uid_t __user *ruid, uid_t __user *euid, uid_t __user *suid);
+asmlinkage long sys_setresgid(gid_t rgid, gid_t egid, gid_t sgid);
+asmlinkage long sys_getresgid(gid_t __user *rgid, gid_t __user *egid, gid_t __user *sgid);
+asmlinkage long sys_setfsuid(uid_t uid);
+asmlinkage long sys_setfsgid(gid_t gid);
+asmlinkage long sys_times(struct tms __user *tbuf);
+asmlinkage long sys_setpgid(pid_t pid, pid_t pgid);
+asmlinkage long sys_getpgid(pid_t pid);
+asmlinkage long sys_getsid(pid_t pid);
+asmlinkage long sys_setsid(void);
+asmlinkage long sys_getgroups(int gidsetsize, gid_t __user *grouplist);
+asmlinkage long sys_setgroups(int gidsetsize, gid_t __user *grouplist);
+asmlinkage long sys_newuname(struct new_utsname __user *name);
+asmlinkage long sys_sethostname(char __user *name, int len);
+asmlinkage long sys_setdomainname(char __user *name, int len);
+asmlinkage long sys_getrlimit(unsigned int resource,
+				struct rlimit __user *rlim);
+asmlinkage long sys_setrlimit(unsigned int resource,
+				struct rlimit __user *rlim);
+asmlinkage long sys_getrusage(int who, struct rusage __user *ru);
+asmlinkage long sys_umask(int mask);
+asmlinkage long sys_prctl(int option, unsigned long arg2, unsigned long arg3,
+			unsigned long arg4, unsigned long arg5);
+asmlinkage long sys_getcpu(unsigned __user *cpu, unsigned __user *node, struct getcpu_cache __user *cache);
+
+/* kernel/time.c */
+asmlinkage long sys_gettimeofday(struct __kernel_old_timeval __user *tv,
+				struct timezone __user *tz);
+asmlinkage long sys_settimeofday(struct __kernel_old_timeval __user *tv,
+				struct timezone __user *tz);
+asmlinkage long sys_adjtimex(struct __kernel_timex __user *txc_p);
+asmlinkage long sys_adjtimex_time32(struct old_timex32 __user *txc_p);
+
+/* kernel/timer.c */
+asmlinkage long sys_getpid(void);
+asmlinkage long sys_getppid(void);
+asmlinkage long sys_getuid(void);
+asmlinkage long sys_geteuid(void);
+asmlinkage long sys_getgid(void);
+asmlinkage long sys_getegid(void);
+asmlinkage long sys_gettid(void);
+asmlinkage long sys_sysinfo(struct sysinfo __user *info);
+
+/* ipc/mqueue.c */
+asmlinkage long sys_mq_open(const char __user *name, int oflag, umode_t mode, struct mq_attr __user *attr);
+asmlinkage long sys_mq_unlink(const char __user *name);
+asmlinkage long sys_mq_timedsend(mqd_t mqdes, const char __user *msg_ptr, size_t msg_len, unsigned int msg_prio, const struct __kernel_timespec __user *abs_timeout);
+asmlinkage long sys_mq_timedreceive(mqd_t mqdes, char __user *msg_ptr, size_t msg_len, unsigned int __user *msg_prio, const struct __kernel_timespec __user *abs_timeout);
+asmlinkage long sys_mq_notify(mqd_t mqdes, const struct sigevent __user *notification);
+asmlinkage long sys_mq_getsetattr(mqd_t mqdes, const struct mq_attr __user *mqstat, struct mq_attr __user *omqstat);
+asmlinkage long sys_mq_timedreceive_time32(mqd_t mqdes,
+			char __user *u_msg_ptr,
+			unsigned int msg_len, unsigned int __user *u_msg_prio,
+			const struct old_timespec32 __user *u_abs_timeout);
+asmlinkage long sys_mq_timedsend_time32(mqd_t mqdes,
+			const char __user *u_msg_ptr,
+			unsigned int msg_len, unsigned int msg_prio,
+			const struct old_timespec32 __user *u_abs_timeout);
+
+/* ipc/msg.c */
+asmlinkage long sys_msgget(key_t key, int msgflg);
+asmlinkage long sys_old_msgctl(int msqid, int cmd, struct msqid_ds __user *buf);
+asmlinkage long sys_msgctl(int msqid, int cmd, struct msqid_ds __user *buf);
+asmlinkage long sys_msgrcv(int msqid, struct msgbuf __user *msgp,
+				size_t msgsz, long msgtyp, int msgflg);
+asmlinkage long sys_msgsnd(int msqid, struct msgbuf __user *msgp,
+				size_t msgsz, int msgflg);
+
+/* ipc/sem.c */
+asmlinkage long sys_semget(key_t key, int nsems, int semflg);
+asmlinkage long sys_semctl(int semid, int semnum, int cmd, unsigned long arg);
+asmlinkage long sys_old_semctl(int semid, int semnum, int cmd, unsigned long arg);
+asmlinkage long sys_semtimedop(int semid, struct sembuf __user *sops,
+				unsigned nsops,
+				const struct __kernel_timespec __user *timeout);
+asmlinkage long sys_semtimedop_time32(int semid, struct sembuf __user *sops,
+				unsigned nsops,
+				const struct old_timespec32 __user *timeout);
+asmlinkage long sys_semop(int semid, struct sembuf __user *sops,
+				unsigned nsops);
+
+/* ipc/shm.c */
+asmlinkage long sys_shmget(key_t key, size_t size, int flag);
+asmlinkage long sys_old_shmctl(int shmid, int cmd, struct shmid_ds __user *buf);
+asmlinkage long sys_shmctl(int shmid, int cmd, struct shmid_ds __user *buf);
+asmlinkage long sys_shmat(int shmid, char __user *shmaddr, int shmflg);
+asmlinkage long sys_shmdt(char __user *shmaddr);
+
+/* net/socket.c */
+asmlinkage long sys_socket(int, int, int);
+asmlinkage long sys_socketpair(int, int, int, int __user *);
+asmlinkage long sys_bind(int, struct sockaddr __user *, int);
+asmlinkage long sys_listen(int, int);
+asmlinkage long sys_accept(int, struct sockaddr __user *, int __user *);
+asmlinkage long sys_connect(int, struct sockaddr __user *, int);
+asmlinkage long sys_getsockname(int, struct sockaddr __user *, int __user *);
+asmlinkage long sys_getpeername(int, struct sockaddr __user *, int __user *);
+asmlinkage long sys_sendto(int, void __user *, size_t, unsigned,
+				struct sockaddr __user *, int);
+asmlinkage long sys_recvfrom(int, void __user *, size_t, unsigned,
+				struct sockaddr __user *, int __user *);
+asmlinkage long sys_setsockopt(int fd, int level, int optname,
+				char __user *optval, int optlen);
+asmlinkage long sys_getsockopt(int fd, int level, int optname,
+				char __user *optval, int __user *optlen);
+asmlinkage long sys_shutdown(int, int);
+asmlinkage long sys_sendmsg(int fd, struct user_msghdr __user *msg, unsigned flags);
+asmlinkage long sys_recvmsg(int fd, struct user_msghdr __user *msg, unsigned flags);
+
+/* mm/filemap.c */
+asmlinkage long sys_readahead(int fd, loff_t offset, size_t count);
+
+/* mm/nommu.c, also with MMU */
+asmlinkage long sys_brk(unsigned long brk);
+asmlinkage long sys_munmap(unsigned long addr, size_t len);
+asmlinkage long sys_mremap(unsigned long addr,
+			   unsigned long old_len, unsigned long new_len,
+			   unsigned long flags, unsigned long new_addr);
+
+/* security/keys/keyctl.c */
+asmlinkage long sys_add_key(const char __user *_type,
+			    const char __user *_description,
+			    const void __user *_payload,
+			    size_t plen,
+			    key_serial_t destringid);
+asmlinkage long sys_request_key(const char __user *_type,
+				const char __user *_description,
+				const char __user *_callout_info,
+				key_serial_t destringid);
+asmlinkage long sys_keyctl(int cmd, unsigned long arg2, unsigned long arg3,
+			   unsigned long arg4, unsigned long arg5);
+
+/* arch/example/kernel/sys_example.c */
+#ifdef CONFIG_CLONE_BACKWARDS
+asmlinkage long sys_clone(unsigned long, unsigned long, int __user *, unsigned long,
+	       int __user *);
+#else
+#ifdef CONFIG_CLONE_BACKWARDS3
+asmlinkage long sys_clone(unsigned long, unsigned long, int, int __user *,
+			  int __user *, unsigned long);
+#else
+asmlinkage long sys_clone(unsigned long, unsigned long, int __user *,
+	       int __user *, unsigned long);
+#endif
+#endif
+
+asmlinkage long sys_clone3(struct clone_args __user *uargs, size_t size);
+
+asmlinkage long sys_execve(const char __user *filename,
+		const char __user *const __user *argv,
+		const char __user *const __user *envp);
+
+/* mm/fadvise.c */
+asmlinkage long sys_fadvise64_64(int fd, loff_t offset, loff_t len, int advice);
+
+/* mm/, CONFIG_MMU only */
+asmlinkage long sys_swapon(const char __user *specialfile, int swap_flags);
+asmlinkage long sys_swapoff(const char __user *specialfile);
+asmlinkage long sys_mprotect(unsigned long start, size_t len,
+				unsigned long prot);
+asmlinkage long sys_msync(unsigned long start, size_t len, int flags);
+asmlinkage long sys_mlock(unsigned long start, size_t len);
+asmlinkage long sys_munlock(unsigned long start, size_t len);
+asmlinkage long sys_mlockall(int flags);
+asmlinkage long sys_munlockall(void);
+asmlinkage long sys_mincore(unsigned long start, size_t len,
+				unsigned char __user * vec);
+asmlinkage long sys_madvise(unsigned long start, size_t len, int behavior);
+asmlinkage long sys_process_madvise(int pidfd, const struct iovec __user *vec,
+			size_t vlen, int behavior, unsigned int flags);
+asmlinkage long sys_remap_file_pages(unsigned long start, unsigned long size,
+			unsigned long prot, unsigned long pgoff,
+			unsigned long flags);
+asmlinkage long sys_mbind(unsigned long start, unsigned long len,
+				unsigned long mode,
+				const unsigned long __user *nmask,
+				unsigned long maxnode,
+				unsigned flags);
+asmlinkage long sys_get_mempolicy(int __user *policy,
+				unsigned long __user *nmask,
+				unsigned long maxnode,
+				unsigned long addr, unsigned long flags);
+asmlinkage long sys_set_mempolicy(int mode, const unsigned long __user *nmask,
+				unsigned long maxnode);
+asmlinkage long sys_migrate_pages(pid_t pid, unsigned long maxnode,
+				const unsigned long __user *from,
+				const unsigned long __user *to);
+asmlinkage long sys_move_pages(pid_t pid, unsigned long nr_pages,
+				const void __user * __user *pages,
+				const int __user *nodes,
+				int __user *status,
+				int flags);
+
+asmlinkage long sys_rt_tgsigqueueinfo(pid_t tgid, pid_t  pid, int sig,
+		siginfo_t __user *uinfo);
+asmlinkage long sys_perf_event_open(
+		struct perf_event_attr __user *attr_uptr,
+		pid_t pid, int cpu, int group_fd, unsigned long flags);
+asmlinkage long sys_accept4(int, struct sockaddr __user *, int __user *, int);
+asmlinkage long sys_recvmmsg(int fd, struct mmsghdr __user *msg,
+			     unsigned int vlen, unsigned flags,
+			     struct __kernel_timespec __user *timeout);
+asmlinkage long sys_recvmmsg_time32(int fd, struct mmsghdr __user *msg,
+			     unsigned int vlen, unsigned flags,
+			     struct old_timespec32 __user *timeout);
+
+asmlinkage long sys_wait4(pid_t pid, int __user *stat_addr,
+				int options, struct rusage __user *ru);
+asmlinkage long sys_prlimit64(pid_t pid, unsigned int resource,
+				const struct rlimit64 __user *new_rlim,
+				struct rlimit64 __user *old_rlim);
+asmlinkage long sys_fanotify_init(unsigned int flags, unsigned int event_f_flags);
+asmlinkage long sys_fanotify_mark(int fanotify_fd, unsigned int flags,
+				  u64 mask, int fd,
+				  const char  __user *pathname);
+asmlinkage long sys_name_to_handle_at(int dfd, const char __user *name,
+				      struct file_handle __user *handle,
+				      int __user *mnt_id, int flag);
+asmlinkage long sys_open_by_handle_at(int mountdirfd,
+				      struct file_handle __user *handle,
+				      int flags);
+asmlinkage long sys_clock_adjtime(clockid_t which_clock,
+				struct __kernel_timex __user *tx);
+asmlinkage long sys_clock_adjtime32(clockid_t which_clock,
+				struct old_timex32 __user *tx);
+asmlinkage long sys_syncfs(int fd);
+asmlinkage long sys_setns(int fd, int nstype);
+asmlinkage long sys_pidfd_open(pid_t pid, unsigned int flags);
+asmlinkage long sys_sendmmsg(int fd, struct mmsghdr __user *msg,
+			     unsigned int vlen, unsigned flags);
+asmlinkage long sys_process_vm_readv(pid_t pid,
+				     const struct iovec __user *lvec,
+				     unsigned long liovcnt,
+				     const struct iovec __user *rvec,
+				     unsigned long riovcnt,
+				     unsigned long flags);
+asmlinkage long sys_process_vm_writev(pid_t pid,
+				      const struct iovec __user *lvec,
+				      unsigned long liovcnt,
+				      const struct iovec __user *rvec,
+				      unsigned long riovcnt,
+				      unsigned long flags);
+asmlinkage long sys_kcmp(pid_t pid1, pid_t pid2, int type,
+			 unsigned long idx1, unsigned long idx2);
+asmlinkage long sys_finit_module(int fd, const char __user *uargs, int flags);
+asmlinkage long sys_sched_setattr(pid_t pid,
+					struct sched_attr __user *attr,
+					unsigned int flags);
+asmlinkage long sys_sched_getattr(pid_t pid,
+					struct sched_attr __user *attr,
+					unsigned int size,
+					unsigned int flags);
+asmlinkage long sys_renameat2(int olddfd, const char __user *oldname,
+			      int newdfd, const char __user *newname,
+			      unsigned int flags);
+asmlinkage long sys_seccomp(unsigned int op, unsigned int flags,
+			    void __user *uargs);
+asmlinkage long sys_getrandom(char __user *buf, size_t count,
+			      unsigned int flags);
+asmlinkage long sys_memfd_create(const char __user *uname_ptr, unsigned int flags);
+asmlinkage long sys_bpf(int cmd, union bpf_attr *attr, unsigned int size);
+asmlinkage long sys_execveat(int dfd, const char __user *filename,
+			const char __user *const __user *argv,
+			const char __user *const __user *envp, int flags);
+asmlinkage long sys_userfaultfd(int flags);
+asmlinkage long sys_membarrier(int cmd, unsigned int flags, int cpu_id);
+asmlinkage long sys_mlock2(unsigned long start, size_t len, int flags);
+asmlinkage long sys_copy_file_range(int fd_in, loff_t __user *off_in,
+				    int fd_out, loff_t __user *off_out,
+				    size_t len, unsigned int flags);
+asmlinkage long sys_preadv2(unsigned long fd, const struct iovec __user *vec,
+			    unsigned long vlen, unsigned long pos_l, unsigned long pos_h,
+			    rwf_t flags);
+asmlinkage long sys_pwritev2(unsigned long fd, const struct iovec __user *vec,
+			    unsigned long vlen, unsigned long pos_l, unsigned long pos_h,
+			    rwf_t flags);
+asmlinkage long sys_pkey_mprotect(unsigned long start, size_t len,
+				  unsigned long prot, int pkey);
+asmlinkage long sys_pkey_alloc(unsigned long flags, unsigned long init_val);
+asmlinkage long sys_pkey_free(int pkey);
+asmlinkage long sys_statx(int dfd, const char __user *path, unsigned flags,
+			  unsigned mask, struct statx __user *buffer);
+asmlinkage long sys_rseq(struct rseq __user *rseq, uint32_t rseq_len,
+			 int flags, uint32_t sig);
+asmlinkage long sys_open_tree(int dfd, const char __user *path, unsigned flags);
+asmlinkage long sys_move_mount(int from_dfd, const char __user *from_path,
+			       int to_dfd, const char __user *to_path,
+			       unsigned int ms_flags);
+asmlinkage long sys_fsopen(const char __user *fs_name, unsigned int flags);
+asmlinkage long sys_fsconfig(int fs_fd, unsigned int cmd, const char __user *key,
+			     const void __user *value, int aux);
+asmlinkage long sys_fsmount(int fs_fd, unsigned int flags, unsigned int ms_flags);
+asmlinkage long sys_fspick(int dfd, const char __user *path, unsigned int flags);
+asmlinkage long sys_pidfd_send_signal(int pidfd, int sig,
+				       siginfo_t __user *info,
+				       unsigned int flags);
+asmlinkage long sys_pidfd_getfd(int pidfd, int fd, unsigned int flags);
+asmlinkage long sys_landlock_create_ruleset(const struct landlock_ruleset_attr __user *attr,
+		size_t size, __u32 flags);
+asmlinkage long sys_landlock_add_rule(int ruleset_fd, enum landlock_rule_type rule_type,
+		const void __user *rule_attr, __u32 flags);
+asmlinkage long sys_landlock_restrict_self(int ruleset_fd, __u32 flags);
+
+/*
+ * Architecture-specific system calls
+ */
+
+/* arch/x86/kernel/ioport.c */
+asmlinkage long sys_ioperm(unsigned long from, unsigned long num, int on);
+
+/* pciconfig: alpha, arm, arm64, ia64, sparc */
+asmlinkage long sys_pciconfig_read(unsigned long bus, unsigned long dfn,
+				unsigned long off, unsigned long len,
+				void __user *buf);
+asmlinkage long sys_pciconfig_write(unsigned long bus, unsigned long dfn,
+				unsigned long off, unsigned long len,
+				void __user *buf);
+asmlinkage long sys_pciconfig_iobase(long which, unsigned long bus, unsigned long devfn);
+
+/* powerpc */
+asmlinkage long sys_spu_run(int fd, __u32 __user *unpc,
+				 __u32 __user *ustatus);
+asmlinkage long sys_spu_create(const char __user *name,
+		unsigned int flags, umode_t mode, int fd);
+
+
+/*
+ * Deprecated system calls which are still defined in
+ * include/uapi/asm-generic/unistd.h and wanted by >= 1 arch
+ */
+
+/* __ARCH_WANT_SYSCALL_NO_AT */
+asmlinkage long sys_open(const char __user *filename,
+				int flags, umode_t mode);
+asmlinkage long sys_link(const char __user *oldname,
+				const char __user *newname);
+asmlinkage long sys_unlink(const char __user *pathname);
+asmlinkage long sys_mknod(const char __user *filename, umode_t mode,
+				unsigned dev);
+asmlinkage long sys_chmod(const char __user *filename, umode_t mode);
+asmlinkage long sys_chown(const char __user *filename,
+				uid_t user, gid_t group);
+asmlinkage long sys_mkdir(const char __user *pathname, umode_t mode);
+asmlinkage long sys_rmdir(const char __user *pathname);
+asmlinkage long sys_lchown(const char __user *filename,
+				uid_t user, gid_t group);
+asmlinkage long sys_access(const char __user *filename, int mode);
+asmlinkage long sys_rename(const char __user *oldname,
+				const char __user *newname);
+asmlinkage long sys_symlink(const char __user *old, const char __user *new);
+#if defined(__ARCH_WANT_STAT64) || defined(__ARCH_WANT_COMPAT_STAT64)
+asmlinkage long sys_stat64(const char __user *filename,
+				struct stat64 __user *statbuf);
+asmlinkage long sys_lstat64(const char __user *filename,
+				struct stat64 __user *statbuf);
+#endif
+
+/* __ARCH_WANT_SYSCALL_NO_FLAGS */
+asmlinkage long sys_pipe(int __user *fildes);
+asmlinkage long sys_dup2(unsigned int oldfd, unsigned int newfd);
+asmlinkage long sys_epoll_create(int size);
+asmlinkage long sys_inotify_init(void);
+asmlinkage long sys_eventfd(unsigned int count);
+asmlinkage long sys_signalfd(int ufd, sigset_t __user *user_mask, size_t sizemask);
+
+/* __ARCH_WANT_SYSCALL_OFF_T */
+asmlinkage long sys_sendfile(int out_fd, int in_fd,
+			     off_t __user *offset, size_t count);
+asmlinkage long sys_newstat(const char __user *filename,
+				struct stat __user *statbuf);
+asmlinkage long sys_newlstat(const char __user *filename,
+				struct stat __user *statbuf);
+asmlinkage long sys_fadvise64(int fd, loff_t offset, size_t len, int advice);
+
+/* __ARCH_WANT_SYSCALL_DEPRECATED */
+asmlinkage long sys_alarm(unsigned int seconds);
+asmlinkage long sys_getpgrp(void);
+asmlinkage long sys_pause(void);
+asmlinkage long sys_time(__kernel_old_time_t __user *tloc);
+asmlinkage long sys_time32(old_time32_t __user *tloc);
+#ifdef __ARCH_WANT_SYS_UTIME
+asmlinkage long sys_utime(char __user *filename,
+				struct utimbuf __user *times);
+asmlinkage long sys_utimes(char __user *filename,
+				struct __kernel_old_timeval __user *utimes);
+asmlinkage long sys_futimesat(int dfd, const char __user *filename,
+			      struct __kernel_old_timeval __user *utimes);
+#endif
+asmlinkage long sys_futimesat_time32(unsigned int dfd,
+				     const char __user *filename,
+				     struct old_timeval32 __user *t);
+asmlinkage long sys_utime32(const char __user *filename,
+				 struct old_utimbuf32 __user *t);
+asmlinkage long sys_utimes_time32(const char __user *filename,
+				  struct old_timeval32 __user *t);
+asmlinkage long sys_creat(const char __user *pathname, umode_t mode);
+asmlinkage long sys_getdents(unsigned int fd,
+				struct linux_dirent __user *dirent,
+				unsigned int count);
+asmlinkage long sys_select(int n, fd_set __user *inp, fd_set __user *outp,
+			fd_set __user *exp, struct __kernel_old_timeval __user *tvp);
+asmlinkage long sys_poll(struct pollfd __user *ufds, unsigned int nfds,
+				int timeout);
+asmlinkage long sys_epoll_wait(int epfd, struct epoll_event __user *events,
+				int maxevents, int timeout);
+asmlinkage long sys_ustat(unsigned dev, struct ustat __user *ubuf);
+asmlinkage long sys_vfork(void);
+asmlinkage long sys_recv(int, void __user *, size_t, unsigned);
+asmlinkage long sys_send(int, void __user *, size_t, unsigned);
+asmlinkage long sys_bdflush(int func, long data);
+asmlinkage long sys_oldumount(char __user *name);
+asmlinkage long sys_uselib(const char __user *library);
+asmlinkage long sys_sysfs(int option,
+				unsigned long arg1, unsigned long arg2);
+asmlinkage long sys_fork(void);
+
+/* obsolete: kernel/time/time.c */
+asmlinkage long sys_stime(__kernel_old_time_t __user *tptr);
+asmlinkage long sys_stime32(old_time32_t __user *tptr);
+
+/* obsolete: kernel/signal.c */
+asmlinkage long sys_sigpending(old_sigset_t __user *uset);
+asmlinkage long sys_sigprocmask(int how, old_sigset_t __user *set,
+				old_sigset_t __user *oset);
+#ifdef CONFIG_OLD_SIGSUSPEND
+asmlinkage long sys_sigsuspend(old_sigset_t mask);
+#endif
+
+#ifdef CONFIG_OLD_SIGSUSPEND3
+asmlinkage long sys_sigsuspend(int unused1, int unused2, old_sigset_t mask);
+#endif
+
+#ifdef CONFIG_OLD_SIGACTION
+asmlinkage long sys_sigaction(int, const struct old_sigaction __user *,
+				struct old_sigaction __user *);
+#endif
+asmlinkage long sys_sgetmask(void);
+asmlinkage long sys_ssetmask(int newmask);
+asmlinkage long sys_signal(int sig, __sighandler_t handler);
+
+/* obsolete: kernel/sched/core.c */
+asmlinkage long sys_nice(int increment);
+
+/* obsolete: kernel/kexec_file.c */
+asmlinkage long sys_kexec_file_load(int kernel_fd, int initrd_fd,
+				    unsigned long cmdline_len,
+				    const char __user *cmdline_ptr,
+				    unsigned long flags);
+
+/* obsolete: kernel/exit.c */
+asmlinkage long sys_waitpid(pid_t pid, int __user *stat_addr, int options);
+
+/* obsolete: kernel/uid16.c */
+#ifdef CONFIG_HAVE_UID16
+asmlinkage long sys_chown16(const char __user *filename,
+				old_uid_t user, old_gid_t group);
+asmlinkage long sys_lchown16(const char __user *filename,
+				old_uid_t user, old_gid_t group);
+asmlinkage long sys_fchown16(unsigned int fd, old_uid_t user, old_gid_t group);
+asmlinkage long sys_setregid16(old_gid_t rgid, old_gid_t egid);
+asmlinkage long sys_setgid16(old_gid_t gid);
+asmlinkage long sys_setreuid16(old_uid_t ruid, old_uid_t euid);
+asmlinkage long sys_setuid16(old_uid_t uid);
+asmlinkage long sys_setresuid16(old_uid_t ruid, old_uid_t euid, old_uid_t suid);
+asmlinkage long sys_getresuid16(old_uid_t __user *ruid,
+				old_uid_t __user *euid, old_uid_t __user *suid);
+asmlinkage long sys_setresgid16(old_gid_t rgid, old_gid_t egid, old_gid_t sgid);
+asmlinkage long sys_getresgid16(old_gid_t __user *rgid,
+				old_gid_t __user *egid, old_gid_t __user *sgid);
+asmlinkage long sys_setfsuid16(old_uid_t uid);
+asmlinkage long sys_setfsgid16(old_gid_t gid);
+asmlinkage long sys_getgroups16(int gidsetsize, old_gid_t __user *grouplist);
+asmlinkage long sys_setgroups16(int gidsetsize, old_gid_t __user *grouplist);
+asmlinkage long sys_getuid16(void);
+asmlinkage long sys_geteuid16(void);
+asmlinkage long sys_getgid16(void);
+asmlinkage long sys_getegid16(void);
+#endif
+
+/* obsolete: net/socket.c */
+asmlinkage long sys_socketcall(int call, unsigned long __user *args);
+
+/* obsolete: fs/stat.c */
+asmlinkage long sys_stat(const char __user *filename,
+			struct __old_kernel_stat __user *statbuf);
+asmlinkage long sys_lstat(const char __user *filename,
+			struct __old_kernel_stat __user *statbuf);
+asmlinkage long sys_fstat(unsigned int fd,
+			struct __old_kernel_stat __user *statbuf);
+asmlinkage long sys_readlink(const char __user *path,
+				char __user *buf, int bufsiz);
+
+/* obsolete: fs/select.c */
+asmlinkage long sys_old_select(struct sel_arg_struct __user *arg);
+
+/* obsolete: fs/readdir.c */
+asmlinkage long sys_old_readdir(unsigned int, struct old_linux_dirent __user *, unsigned int);
+
+/* obsolete: kernel/sys.c */
+asmlinkage long sys_gethostname(char __user *name, int len);
+asmlinkage long sys_uname(struct old_utsname __user *);
+asmlinkage long sys_olduname(struct oldold_utsname __user *);
+#ifdef __ARCH_WANT_SYS_OLD_GETRLIMIT
+asmlinkage long sys_old_getrlimit(unsigned int resource, struct rlimit __user *rlim);
+#endif
+
+/* obsolete: ipc */
+asmlinkage long sys_ipc(unsigned int call, int first, unsigned long second,
+		unsigned long third, void __user *ptr, long fifth);
+
+/* obsolete: mm/ */
+asmlinkage long sys_mmap_pgoff(unsigned long addr, unsigned long len,
+			unsigned long prot, unsigned long flags,
+			unsigned long fd, unsigned long pgoff);
+asmlinkage long sys_old_mmap(struct mmap_arg_struct __user *arg);
+
+
+/*
+ * Not a real system call, but a placeholder for syscalls which are
+ * not implemented -- see kernel/sys_ni.c
+ */
+asmlinkage long sys_ni_syscall(void);
+
+#endif /* CONFIG_ARCH_HAS_SYSCALL_WRAPPER */
+
+
+/*
+ * Kernel code should not call syscalls (i.e., sys_xyzyyz()) directly.
+ * Instead, use one of the functions which work equivalently, such as
+ * the ksys_xyzyyz() functions prototyped below.
+ */
+ssize_t ksys_write(unsigned int fd, const char __user *buf, size_t count);
+int ksys_fchown(unsigned int fd, uid_t user, gid_t group);
+ssize_t ksys_read(unsigned int fd, char __user *buf, size_t count);
+void ksys_sync(void);
+int ksys_unshare(unsigned long unshare_flags);
+int ksys_setsid(void);
+int ksys_sync_file_range(int fd, loff_t offset, loff_t nbytes,
+			 unsigned int flags);
+ssize_t ksys_pread64(unsigned int fd, char __user *buf, size_t count,
+		     loff_t pos);
+ssize_t ksys_pwrite64(unsigned int fd, const char __user *buf,
+		      size_t count, loff_t pos);
+int ksys_fallocate(int fd, int mode, loff_t offset, loff_t len);
+#ifdef CONFIG_ADVISE_SYSCALLS
+int ksys_fadvise64_64(int fd, loff_t offset, loff_t len, int advice);
+#else
+static inline int ksys_fadvise64_64(int fd, loff_t offset, loff_t len,
+				    int advice)
+{
+	return -EINVAL;
+}
+#endif
+unsigned long ksys_mmap_pgoff(unsigned long addr, unsigned long len,
+			      unsigned long prot, unsigned long flags,
+			      unsigned long fd, unsigned long pgoff);
+ssize_t ksys_readahead(int fd, loff_t offset, size_t count);
+int ksys_ipc(unsigned int call, int first, unsigned long second,
+	unsigned long third, void __user * ptr, long fifth);
+int compat_ksys_ipc(u32 call, int first, int second,
+	u32 third, u32 ptr, u32 fifth);
+
+/*
+ * The following kernel syscall equivalents are just wrappers to fs-internal
+ * functions. Therefore, provide stubs to be inlined at the callsites.
+ */
+extern int do_fchownat(int dfd, const char __user *filename, uid_t user,
+		       gid_t group, int flag);
+
+static inline long ksys_chown(const char __user *filename, uid_t user,
+			      gid_t group)
+{
+	return do_fchownat(AT_FDCWD, filename, user, group, 0);
+}
+
+static inline long ksys_lchown(const char __user *filename, uid_t user,
+			       gid_t group)
+{
+	return do_fchownat(AT_FDCWD, filename, user, group,
+			     AT_SYMLINK_NOFOLLOW);
+}
+
+extern long do_sys_ftruncate(unsigned int fd, loff_t length, int small);
+
+static inline long ksys_ftruncate(unsigned int fd, loff_t length)
+{
+	return do_sys_ftruncate(fd, length, 1);
+}
+
+extern int __close_fd(struct files_struct *files, unsigned int fd);
+
+/*
+ * In contrast to sys_close(), this stub does not check whether the syscall
+ * should or should not be restarted, but returns the raw error codes from
+ * __close_fd().
+ */
+static inline int ksys_close(unsigned int fd)
+{
+	return __close_fd(current->files, fd);
+}
+
+extern long do_sys_truncate(const char __user *pathname, loff_t length);
+
+static inline long ksys_truncate(const char __user *pathname, loff_t length)
+{
+	return do_sys_truncate(pathname, length);
+}
+
+static inline unsigned int ksys_personality(unsigned int personality)
+{
+	unsigned int old = current->personality;
+
+	if (personality != 0xffffffff)
+		set_personality(personality);
+
+	return old;
+}
+
+/* for __ARCH_WANT_SYS_IPC */
+long ksys_semtimedop(int semid, struct sembuf __user *tsops,
+		     unsigned int nsops,
+		     const struct __kernel_timespec __user *timeout);
+long ksys_semget(key_t key, int nsems, int semflg);
+long ksys_old_semctl(int semid, int semnum, int cmd, unsigned long arg);
+long ksys_msgget(key_t key, int msgflg);
+long ksys_old_msgctl(int msqid, int cmd, struct msqid_ds __user *buf);
+long ksys_msgrcv(int msqid, struct msgbuf __user *msgp, size_t msgsz,
+		 long msgtyp, int msgflg);
+long ksys_msgsnd(int msqid, struct msgbuf __user *msgp, size_t msgsz,
+		 int msgflg);
+long ksys_shmget(key_t key, size_t size, int shmflg);
+long ksys_shmdt(char __user *shmaddr);
+long ksys_old_shmctl(int shmid, int cmd, struct shmid_ds __user *buf);
+long compat_ksys_semtimedop(int semid, struct sembuf __user *tsems,
+			    unsigned int nsops,
+			    const struct old_timespec32 __user *timeout);
+
+int __sys_getsockopt(int fd, int level, int optname, char __user *optval,
+		int __user *optlen);
+int __sys_setsockopt(int fd, int level, int optname, char __user *optval,
+		int optlen);
+
+/* Only used with ALT_SYSCALL enabled */
+
+int ksys_prctl(int option, unsigned long arg2, unsigned long arg3,
+	       unsigned long arg4, unsigned long arg5);
+int ksys_setpriority(int which, int who, int niceval);
+int ksys_getpriority(int which, int who);
+int ksys_perf_event_open(
+		struct perf_event_attr __user *attr_uptr,
+		pid_t pid, int cpu, int group_fd, unsigned long flags);
+int ksys_kcmp(pid_t pid1, pid_t pid2, int type,
+		unsigned long idx1, unsigned long idx2);
+int ksys_clock_adjtime(const clockid_t which_clock, struct __kernel_timex __user * utx);
+int ksys_adjtimex(struct __kernel_timex __user *txc_p);
+int ksys_getcpu(unsigned __user *cpu, unsigned __user *node,
+		struct getcpu_cache __user *cache);
+int ksys_clock_adjtime32(clockid_t which_clock,
+			 struct old_timex32 __user *utp);
+int ksys_adjtimex_time32(struct old_timex32 __user *utp);
+
+#endif
diff --git a/drivers/virtio/virtio_wl.c b/drivers/virtio/virtio_wl.c
new file mode 100644
index 000000000000..39e57d943e18
--- /dev/null
+++ b/drivers/virtio/virtio_wl.c
@@ -0,0 +1,1387 @@
+/*
+ *  Wayland Virtio Driver
+ *  Copyright (C) 2017 Google, Inc.
+ *
+ *  This program is free software; you can redistribute it and/or modify
+ *  it under the terms of the GNU General Public License as published by
+ *  the Free Software Foundation; either version 2 of the License, or
+ *  (at your option) any later version.
+ *
+ *  This program is distributed in the hope that it will be useful,
+ *  but WITHOUT ANY WARRANTY; without even the implied warranty of
+ *  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ *  GNU General Public License for more details.
+ *
+ */
+/*
+ * Virtio Wayland (virtio_wl or virtwl) is a virtual device that allows a guest
+ * virtual machine to use a wayland server on the host transparently (to the
+ * host).  This is done by proxying the wayland protocol socket stream verbatim
+ * between the host and guest over 2 (recv and send) virtio queues. The guest
+ * can request new wayland server connections to give each guest wayland client
+ * a different server context. Each host connection's file descriptor is exposed
+ * to the guest as a virtual file descriptor (VFD). Additionally, the guest can
+ * request shared memory file descriptors which are also exposed as VFDs. These
+ * shared memory VFDs are directly writable by the guest via device memory
+ * injected by the host. Each VFD is sendable along a connection context VFD and
+ * will appear as ancillary data to the wayland server, just like a message from
+ * an ordinary wayland client. When the wayland server sends a shared memory
+ * file descriptor to the client (such as when sending a keymap), a VFD is
+ * allocated by the device automatically and its memory is injected into as
+ * device memory.
+ *
+ * This driver is intended to be paired with the `virtwl_guest_proxy` program
+ * which is run in the guest system and acts like a wayland server. It accepts
+ * wayland client connections and converts their socket messages to ioctl
+ * messages exposed by this driver via the `/dev/wl` device file. While it would
+ * be possible to expose a unix stream socket from this driver, the user space
+ * helper is much cleaner to write.
+ */
+#include <linux/anon_inodes.h>
+#include <linux/cdev.h>
+#include <linux/compat.h>
+#include <linux/completion.h>
+#include <linux/dma-buf.h>
+#include <linux/err.h>
+#include <linux/fdtable.h>
+#include <linux/file.h>
+#include <linux/fs.h>
+#include <linux/idr.h>
+#include <linux/kfifo.h>
+#include <linux/module.h>
+#include <linux/mutex.h>
+#include <linux/poll.h>
+#include <linux/scatterlist.h>
+#include <linux/syscalls.h>
+#include <linux/uaccess.h>
+#include <linux/virtio.h>
+#include <linux/virtio_dma_buf.h>
+#include "virtio_wl.h"
+#include <linux/vmalloc.h>
+#include <uapi/linux/dma-buf.h>
+#include "internal.h"
+/* #include "syscall.h" */
+
+/* extern int __close_fd(struct files_struct *files, unsigned int fd); */
+int __close_fd(struct files_struct *files, unsigned int fd)
+{return -1;}
+
+#if 0    /* TODO */
+int find_vm_area(struct vm_struct *vma)
+{return -1;}
+#endif
+
+static inline int ksys_close(unsigned int fd)
+{
+	return __close_fd(current->files, fd);
+}
+
+#define VIRTIO_WL_F_USE_SHMEM 3
+
+#ifdef CONFIG_DRM_VIRTIO_GPU
+
+#endif
+#define VFD_ILLEGAL_SIGN_BIT 0x80000000
+#define VFD_HOST_VFD_ID_BIT 0x40000000
+struct virtwl_vfd_qentry {
+	struct list_head list;
+	struct virtio_wl_ctrl_hdr *hdr;
+	unsigned int len; /* total byte length of ctrl_vfd_* + vfds + data */
+	unsigned int vfd_offset; /* int offset into vfds */
+	unsigned int data_offset; /* byte offset into data */
+};
+struct virtwl_vfd {
+	struct kobject kobj;
+	struct mutex lock;
+	struct virtwl_info *vi;
+	uint32_t id;
+	uint32_t flags;
+	uint64_t pfn;
+	uint32_t size;
+	bool hungup;
+	struct list_head in_queue; /* list of virtwl_vfd_qentry */
+	wait_queue_head_t in_waitq;
+};
+struct virtwl_info {
+	dev_t dev_num;
+	struct device *dev;
+	struct class *class;
+	struct cdev cdev;
+	struct mutex vq_locks[VIRTWL_QUEUE_COUNT];
+	struct virtqueue *vqs[VIRTWL_QUEUE_COUNT];
+	struct work_struct in_vq_work;
+	struct work_struct out_vq_work;
+	wait_queue_head_t out_waitq;
+	struct mutex vfds_lock;
+	struct idr vfds;
+	bool use_send_vfd_v2;
+	// Base value to use when deriving pfn values from vfd pfn offsets
+	u64 pfn_base;
+	// Pfn value sent by the device to indicate the vfd has no pfn.
+	u64 invalid_pfn;
+};
+static struct virtwl_vfd *virtwl_vfd_alloc(struct virtwl_info *vi);
+static void virtwl_vfd_free(struct virtwl_vfd *vfd);
+static const struct file_operations virtwl_vfd_fops;
+static int virtwl_resp_err(unsigned int type)
+{
+	switch (type) {
+	case VIRTIO_WL_RESP_OK:
+	case VIRTIO_WL_RESP_VFD_NEW:
+	case VIRTIO_WL_RESP_VFD_NEW_DMABUF:
+		return 0;
+	case VIRTIO_WL_RESP_ERR:
+		return -ENODEV; /* Device is no longer reliable */
+	case VIRTIO_WL_RESP_OUT_OF_MEMORY:
+		return -ENOMEM;
+	case VIRTIO_WL_RESP_INVALID_ID:
+		return -ENOENT;
+	case VIRTIO_WL_RESP_INVALID_TYPE:
+		return -EINVAL;
+	case VIRTIO_WL_RESP_INVALID_FLAGS:
+		return -EPERM;
+	case VIRTIO_WL_RESP_INVALID_CMD:
+		return -ENOTTY;
+	default:
+		return -EPROTO;
+	}
+}
+static int vq_return_inbuf_locked(struct virtqueue *vq, void *buffer)
+{
+	int ret;
+	struct scatterlist sg[1];
+	sg_init_one(sg, buffer, PAGE_SIZE);
+	ret = virtqueue_add_inbuf(vq, sg, 1, buffer, GFP_KERNEL);
+	if (ret) {
+		pr_warn("virtwl: failed to give inbuf to host: %d\n", ret);
+		return ret;
+	}
+	return 0;
+}
+static int vq_queue_out(struct virtwl_info *vi, struct scatterlist *out_sg,
+			struct scatterlist *in_sg,
+			struct completion *finish_completion,
+			bool nonblock)
+{
+	struct virtqueue *vq = vi->vqs[VIRTWL_VQ_OUT];
+	struct mutex *vq_lock = &vi->vq_locks[VIRTWL_VQ_OUT];
+	struct scatterlist *sgs[] = { out_sg, in_sg };
+	int ret = 0;
+	mutex_lock(vq_lock);
+	while ((ret = virtqueue_add_sgs(vq, sgs, 1, 1, finish_completion,
+					GFP_KERNEL)) == -ENOSPC) {
+		mutex_unlock(vq_lock);
+		if (nonblock)
+			return -EAGAIN;
+		if (!wait_event_timeout(vi->out_waitq, vq->num_free > 0, HZ))
+			return -EBUSY;
+		mutex_lock(vq_lock);
+	}
+	if (!ret)
+		virtqueue_kick(vq);
+	mutex_unlock(vq_lock);
+	return ret;
+}
+static int vq_fill_locked(struct virtqueue *vq)
+{
+	void *buffer;
+	int ret = 0;
+	while (vq->num_free > 0) {
+		buffer = kmalloc(PAGE_SIZE, GFP_KERNEL);
+		if (!buffer) {
+			ret = -ENOMEM;
+			goto clear_queue;
+		}
+		ret = vq_return_inbuf_locked(vq, buffer);
+		if (ret)
+			goto clear_queue;
+	}
+	return 0;
+clear_queue:
+	while ((buffer = virtqueue_detach_unused_buf(vq)))
+		kfree(buffer);
+	return ret;
+}
+static uint64_t decode_pfn(struct virtwl_info *vi,
+			   struct virtio_wl_ctrl_vfd_new *new)
+{
+	if (new->pfn == vi->invalid_pfn)
+		return 0;
+	return new->pfn + vi->pfn_base;
+}
+static bool vq_handle_new(struct virtwl_info *vi,
+			  struct virtio_wl_ctrl_vfd_new *new, unsigned int len)
+{
+	struct virtwl_vfd *vfd;
+	u32 id = new->vfd_id;
+	int ret;
+	if (id == 0)
+		return true; /* return the inbuf to vq */
+	if (!(id & VFD_HOST_VFD_ID_BIT) || (id & VFD_ILLEGAL_SIGN_BIT)) {
+		pr_warn("virtwl: received a vfd with invalid id: %u\n", id);
+		return true; /* return the inbuf to vq */
+	}
+	vfd = virtwl_vfd_alloc(vi);
+	if (!vfd)
+		return true; /* return the inbuf to vq */
+	mutex_lock(&vi->vfds_lock);
+	ret = idr_alloc(&vi->vfds, vfd, id, id + 1, GFP_KERNEL);
+	mutex_unlock(&vi->vfds_lock);
+	if (ret <= 0) {
+		virtwl_vfd_free(vfd);
+		pr_warn("virtwl: failed to place received vfd: %d\n", ret);
+		return true; /* return the inbuf to vq */
+	}
+	vfd->id = id;
+	vfd->size = new->size;
+	vfd->pfn = decode_pfn(vi, new);
+	vfd->flags = new->flags;
+	return true; /* return the inbuf to vq */
+}
+static bool vq_handle_recv(struct virtwl_info *vi,
+			   struct virtio_wl_ctrl_vfd_recv *recv,
+			   unsigned int len)
+{
+	struct virtwl_vfd *vfd;
+	struct virtwl_vfd_qentry *qentry;
+	mutex_lock(&vi->vfds_lock);
+	vfd = idr_find(&vi->vfds, recv->vfd_id);
+	if (vfd)
+		mutex_lock(&vfd->lock);
+	mutex_unlock(&vi->vfds_lock);
+	if (!vfd) {
+		pr_warn("virtwl: recv for unknown vfd_id %u\n", recv->vfd_id);
+		return true; /* return the inbuf to vq */
+	}
+	qentry = kzalloc(sizeof(*qentry), GFP_KERNEL);
+	if (!qentry) {
+		mutex_unlock(&vfd->lock);
+		pr_warn("virtwl: failed to allocate qentry for vfd\n");
+		return true; /* return the inbuf to vq */
+	}
+	qentry->hdr = &recv->hdr;
+	qentry->len = len;
+	list_add_tail(&qentry->list, &vfd->in_queue);
+	wake_up_interruptible_all(&vfd->in_waitq);
+	mutex_unlock(&vfd->lock);
+	return false; /* no return the inbuf to vq */
+}
+static bool vq_handle_hup(struct virtwl_info *vi,
+			   struct virtio_wl_ctrl_vfd *vfd_hup,
+			   unsigned int len)
+{
+	struct virtwl_vfd *vfd;
+	mutex_lock(&vi->vfds_lock);
+	vfd = idr_find(&vi->vfds, vfd_hup->vfd_id);
+	if (vfd)
+		mutex_lock(&vfd->lock);
+	mutex_unlock(&vi->vfds_lock);
+	if (!vfd) {
+		pr_warn("virtwl: hup for unknown vfd_id %u\n", vfd_hup->vfd_id);
+		return true; /* return the inbuf to vq */
+	}
+	if (vfd->hungup)
+		pr_warn("virtwl: hup for hungup vfd_id %u\n", vfd_hup->vfd_id);
+	vfd->hungup = true;
+	wake_up_interruptible_all(&vfd->in_waitq);
+	mutex_unlock(&vfd->lock);
+	return true;
+}
+static bool vq_dispatch_hdr(struct virtwl_info *vi, unsigned int len,
+			    struct virtio_wl_ctrl_hdr *hdr)
+{
+	struct virtqueue *vq = vi->vqs[VIRTWL_VQ_IN];
+	struct mutex *vq_lock = &vi->vq_locks[VIRTWL_VQ_IN];
+	bool return_vq = true;
+	int ret;
+	switch (hdr->type) {
+	case VIRTIO_WL_CMD_VFD_NEW:
+		return_vq = vq_handle_new(vi,
+					  (struct virtio_wl_ctrl_vfd_new *)hdr,
+					  len);
+		break;
+	case VIRTIO_WL_CMD_VFD_RECV:
+		return_vq = vq_handle_recv(vi,
+			(struct virtio_wl_ctrl_vfd_recv *)hdr, len);
+		break;
+	case VIRTIO_WL_CMD_VFD_HUP:
+		return_vq = vq_handle_hup(vi, (struct virtio_wl_ctrl_vfd *)hdr,
+					  len);
+		break;
+	default:
+		pr_warn("virtwl: unhandled ctrl command: %u\n", hdr->type);
+		break;
+	}
+	if (!return_vq)
+		return false; /* no kick the vq */
+	mutex_lock(vq_lock);
+	ret = vq_return_inbuf_locked(vq, hdr);
+	mutex_unlock(vq_lock);
+	if (ret) {
+		pr_warn("virtwl: failed to return inbuf to host: %d\n", ret);
+		kfree(hdr);
+	}
+	return true; /* kick the vq */
+}
+static void vq_in_work_handler(struct work_struct *work)
+{
+	struct virtwl_info *vi = container_of(work, struct virtwl_info,
+					      in_vq_work);
+	struct virtqueue *vq = vi->vqs[VIRTWL_VQ_IN];
+	struct mutex *vq_lock = &vi->vq_locks[VIRTWL_VQ_IN];
+	void *buffer;
+	unsigned int len;
+	bool kick_vq = false;
+	mutex_lock(vq_lock);
+	while ((buffer = virtqueue_get_buf(vq, &len)) != NULL) {
+		struct virtio_wl_ctrl_hdr *hdr = buffer;
+		mutex_unlock(vq_lock);
+		kick_vq |= vq_dispatch_hdr(vi, len, hdr);
+		mutex_lock(vq_lock);
+	}
+	mutex_unlock(vq_lock);
+	if (kick_vq)
+		virtqueue_kick(vq);
+}
+static void vq_out_work_handler(struct work_struct *work)
+{
+	struct virtwl_info *vi = container_of(work, struct virtwl_info,
+					      out_vq_work);
+	struct virtqueue *vq = vi->vqs[VIRTWL_VQ_OUT];
+	struct mutex *vq_lock = &vi->vq_locks[VIRTWL_VQ_OUT];
+	unsigned int len;
+	struct completion *finish_completion;
+	bool wake_waitq = false;
+	mutex_lock(vq_lock);
+	while ((finish_completion = virtqueue_get_buf(vq, &len)) != NULL) {
+		wake_waitq = true;
+		complete(finish_completion);
+	}
+	mutex_unlock(vq_lock);
+	if (wake_waitq)
+		wake_up_interruptible_all(&vi->out_waitq);
+}
+static void vq_in_cb(struct virtqueue *vq)
+{
+	struct virtwl_info *vi = vq->vdev->priv;
+	schedule_work(&vi->in_vq_work);
+}
+static void vq_out_cb(struct virtqueue *vq)
+{
+	struct virtwl_info *vi = vq->vdev->priv;
+	schedule_work(&vi->out_vq_work);
+}
+static struct virtwl_vfd *virtwl_vfd_alloc(struct virtwl_info *vi)
+{
+	struct virtwl_vfd *vfd = kzalloc(sizeof(struct virtwl_vfd), GFP_KERNEL);
+	if (!vfd)
+		return ERR_PTR(-ENOMEM);
+	vfd->vi = vi;
+	mutex_init(&vfd->lock);
+	INIT_LIST_HEAD(&vfd->in_queue);
+	init_waitqueue_head(&vfd->in_waitq);
+	return vfd;
+}
+static int virtwl_vfd_file_flags(struct virtwl_vfd *vfd)
+{
+	int flags = 0;
+	int rw_mask = VIRTIO_WL_VFD_WRITE | VIRTIO_WL_VFD_READ;
+	if ((vfd->flags & rw_mask) == rw_mask)
+		flags |= O_RDWR;
+	else if (vfd->flags & VIRTIO_WL_VFD_WRITE)
+		flags |= O_WRONLY;
+	else if (vfd->flags & VIRTIO_WL_VFD_READ)
+		flags |= O_RDONLY;
+	if (vfd->pfn)
+		flags |= O_RDWR;
+	return flags;
+}
+/* Locks the vfd and unlinks its id from vi */
+static void virtwl_vfd_lock_unlink(struct virtwl_vfd *vfd)
+{
+	struct virtwl_info *vi = vfd->vi;
+	/* this order is important to avoid deadlock */
+	mutex_lock(&vi->vfds_lock);
+	mutex_lock(&vfd->lock);
+	idr_remove(&vi->vfds, vfd->id);
+	mutex_unlock(&vfd->lock);
+	mutex_unlock(&vi->vfds_lock);
+}
+/*
+ * Only used to free a vfd that is not referenced any place else and contains
+ * no queed virtio buffers. This must not be called while vfd is included in a
+ * vi->vfd.
+ */
+static void virtwl_vfd_free(struct virtwl_vfd *vfd)
+{
+	kfree(vfd);
+}
+/*
+ * Thread safe and also removes vfd from vi as well as any queued virtio buffers
+ */
+static void virtwl_vfd_remove(struct virtwl_vfd *vfd)
+{
+	struct virtwl_info *vi = vfd->vi;
+	struct virtqueue *vq = vi->vqs[VIRTWL_VQ_IN];
+	struct mutex *vq_lock = &vi->vq_locks[VIRTWL_VQ_IN];
+	struct virtwl_vfd_qentry *qentry, *next;
+	virtwl_vfd_lock_unlink(vfd);
+	mutex_lock(vq_lock);
+	list_for_each_entry_safe(qentry, next, &vfd->in_queue, list) {
+		vq_return_inbuf_locked(vq, qentry->hdr);
+		list_del(&qentry->list);
+		kfree(qentry);
+	}
+	mutex_unlock(vq_lock);
+	virtqueue_kick(vq);
+	virtwl_vfd_free(vfd);
+}
+static void vfd_qentry_free_if_empty(struct virtwl_vfd *vfd,
+				     struct virtwl_vfd_qentry *qentry)
+{
+	struct virtwl_info *vi = vfd->vi;
+	struct virtqueue *vq = vi->vqs[VIRTWL_VQ_IN];
+	struct mutex *vq_lock = &vi->vq_locks[VIRTWL_VQ_IN];
+	if (qentry->hdr->type == VIRTIO_WL_CMD_VFD_RECV) {
+		struct virtio_wl_ctrl_vfd_recv *recv =
+			(struct virtio_wl_ctrl_vfd_recv *)qentry->hdr;
+		ssize_t data_len =
+			(ssize_t)qentry->len - (ssize_t)sizeof(*recv) -
+			(ssize_t)recv->vfd_count * (ssize_t)sizeof(__le32);
+		if (qentry->vfd_offset < recv->vfd_count)
+			return;
+		if ((s64)qentry->data_offset < data_len)
+			return;
+	}
+	mutex_lock(vq_lock);
+	vq_return_inbuf_locked(vq, qentry->hdr);
+	mutex_unlock(vq_lock);
+	list_del(&qentry->list);
+	kfree(qentry);
+	virtqueue_kick(vq);
+}
+static ssize_t vfd_out_locked(struct virtwl_vfd *vfd, char __user *buffer,
+			      size_t len)
+{
+	struct virtwl_vfd_qentry *qentry, *next;
+	ssize_t read_count = 0;
+	list_for_each_entry_safe(qentry, next, &vfd->in_queue, list) {
+		struct virtio_wl_ctrl_vfd_recv *recv =
+			(struct virtio_wl_ctrl_vfd_recv *)qentry->hdr;
+		size_t recv_offset = sizeof(*recv) + recv->vfd_count *
+				     sizeof(__le32) + qentry->data_offset;
+		u8 *buf = (u8 *)recv + recv_offset;
+		ssize_t to_read = (ssize_t)qentry->len - (ssize_t)recv_offset;
+		if (qentry->hdr->type != VIRTIO_WL_CMD_VFD_RECV)
+			continue;
+		if ((to_read + read_count) > len)
+			to_read = len - read_count;
+		if (copy_to_user(buffer + read_count, buf, to_read)) {
+			read_count = -EFAULT;
+			break;
+		}
+		read_count += to_read;
+		qentry->data_offset += to_read;
+		vfd_qentry_free_if_empty(vfd, qentry);
+		if (read_count >= len)
+			break;
+	}
+	return read_count;
+}
+/* must hold both vfd->lock and vi->vfds_lock */
+static size_t vfd_out_vfds_locked(struct virtwl_vfd *vfd,
+				  struct virtwl_vfd **vfds, size_t count)
+{
+	struct virtwl_info *vi = vfd->vi;
+	struct virtwl_vfd_qentry *qentry, *next;
+	size_t i;
+	size_t read_count = 0;
+	list_for_each_entry_safe(qentry, next, &vfd->in_queue, list) {
+		struct virtio_wl_ctrl_vfd_recv *recv =
+			(struct virtio_wl_ctrl_vfd_recv *)qentry->hdr;
+		size_t vfd_offset = sizeof(*recv) + qentry->vfd_offset *
+				    sizeof(__le32);
+		__le32 *vfds_le = (__le32 *)((void *)recv + vfd_offset);
+		ssize_t vfds_to_read = recv->vfd_count - qentry->vfd_offset;
+		if (read_count >= count)
+			break;
+		if (vfds_to_read <= 0)
+			continue;
+		if (qentry->hdr->type != VIRTIO_WL_CMD_VFD_RECV)
+			continue;
+		if ((vfds_to_read + read_count) > count)
+			vfds_to_read = count - read_count;
+		for (i = 0; i < vfds_to_read; i++) {
+			uint32_t vfd_id = le32_to_cpu(vfds_le[i]);
+			vfds[read_count] = idr_find(&vi->vfds, vfd_id);
+			if (vfds[read_count]) {
+				read_count++;
+			} else {
+				pr_warn("virtwl: received a vfd with unrecognized id: %u\n",
+					vfd_id);
+			}
+			qentry->vfd_offset++;
+		}
+		vfd_qentry_free_if_empty(vfd, qentry);
+	}
+	return read_count;
+}
+/* this can only be called if the caller has unique ownership of the vfd */
+static int do_vfd_close(struct virtwl_vfd *vfd)
+{
+	struct virtio_wl_ctrl_vfd *ctrl_close;
+	struct virtwl_info *vi = vfd->vi;
+	struct completion finish_completion;
+	struct scatterlist out_sg;
+	struct scatterlist in_sg;
+	int ret = 0;
+	ctrl_close = kzalloc(sizeof(*ctrl_close), GFP_KERNEL);
+	if (!ctrl_close)
+		return -ENOMEM;
+	ctrl_close->hdr.type = VIRTIO_WL_CMD_VFD_CLOSE;
+	ctrl_close->vfd_id = vfd->id;
+	sg_init_one(&out_sg, &ctrl_close->hdr,
+		    sizeof(struct virtio_wl_ctrl_vfd));
+	sg_init_one(&in_sg, &ctrl_close->hdr,
+		    sizeof(struct virtio_wl_ctrl_hdr));
+	init_completion(&finish_completion);
+	ret = vq_queue_out(vi, &out_sg, &in_sg, &finish_completion,
+			   false /* block */);
+	if (ret) {
+		pr_warn("virtwl: failed to queue close vfd id %u: %d\n",
+			vfd->id,
+			ret);
+		goto free_ctrl_close;
+	}
+	wait_for_completion(&finish_completion);
+	virtwl_vfd_remove(vfd);
+free_ctrl_close:
+	kfree(ctrl_close);
+	return ret;
+}
+static ssize_t virtwl_vfd_recv(struct file *filp, char __user *buffer,
+			       size_t len, struct virtwl_vfd **vfds,
+			       size_t *vfd_count)
+{
+	struct virtwl_vfd *vfd = filp->private_data;
+	struct virtwl_info *vi = vfd->vi;
+	ssize_t read_count = 0;
+	size_t vfd_read_count = 0;
+	bool force_to_wait = false;
+	mutex_lock(&vi->vfds_lock);
+	mutex_lock(&vfd->lock);
+	while (read_count == 0 && vfd_read_count == 0) {
+		while (force_to_wait || list_empty(&vfd->in_queue)) {
+			force_to_wait = false;
+			if (vfd->hungup)
+				goto out_unlock;
+			mutex_unlock(&vfd->lock);
+			mutex_unlock(&vi->vfds_lock);
+			if (filp->f_flags & O_NONBLOCK)
+				return -EAGAIN;
+			if (wait_event_interruptible(vfd->in_waitq,
+				!list_empty(&vfd->in_queue) || vfd->hungup))
+				return -ERESTARTSYS;
+			mutex_lock(&vi->vfds_lock);
+			mutex_lock(&vfd->lock);
+		}
+		read_count = vfd_out_locked(vfd, buffer, len);
+		if (read_count < 0)
+			goto out_unlock;
+		if (vfds && vfd_count && *vfd_count)
+			vfd_read_count = vfd_out_vfds_locked(vfd, vfds,
+							     *vfd_count);
+		else if (read_count == 0 && !list_empty(&vfd->in_queue))
+			/*
+			 * Indicates a corner case where the in_queue has ONLY
+			 * incoming VFDs but the caller has given us no space to
+			 * store them. We force a wait for more activity on the
+			 * in_queue to prevent busy waiting.
+			 */
+			force_to_wait = true;
+	}
+out_unlock:
+	mutex_unlock(&vfd->lock);
+	mutex_unlock(&vi->vfds_lock);
+	if (vfd_count)
+		*vfd_count = vfd_read_count;
+	return read_count;
+}
+static int encode_vfd_ids(struct virtwl_vfd **vfds, size_t vfd_count,
+			  __le32 *vfd_ids)
+{
+	size_t i;
+	for (i = 0; i < vfd_count; i++) {
+		if (vfds[i])
+			vfd_ids[i] = cpu_to_le32(vfds[i]->id);
+		else
+			return -EBADFD;
+	}
+	return 0;
+}
+#ifdef SEND_VIRTGPU_RESOURCES
+static int get_dma_buf_id(struct dma_buf *dma_buf, u32 *id)
+{
+	uuid_t uuid;
+	int ret = 0;
+	ret = virtio_dma_buf_get_uuid(dma_buf, &uuid);
+	*id = be32_to_cpu(*(__be32 *)(uuid.b + 12));
+	return ret;
+}
+static int encode_fence(struct dma_fence *fence,
+			struct virtio_wl_ctrl_vfd_send_vfd_v2 *vfd_id)
+{
+	const char *name = fence->ops->get_driver_name(fence);
+	// We only support virtgpu based fences. Since all virtgpu fences are
+	// in the same context, merging sync_files will always reduce to a
+	// single virtgpu fence.
+	if (strcmp(name, "virtio_gpu") != 0)
+		return -EBADFD;
+	if (dma_fence_is_signaled(fence)) {
+		vfd_id->kind =
+			VIRTIO_WL_CTRL_VFD_SEND_KIND_VIRTGPU_SIGNALED_FENCE;
+	} else {
+		vfd_id->kind = VIRTIO_WL_CTRL_VFD_SEND_KIND_VIRTGPU_FENCE;
+		vfd_id->seqno = cpu_to_le32(fence->seqno);
+	}
+	return 0;
+}
+static int encode_vfd_ids_foreign(struct virtwl_vfd **vfds,
+				  struct dma_buf **virtgpu_dma_bufs,
+				  struct dma_fence **virtgpu_dma_fence,
+				  size_t vfd_count,
+				  struct virtio_wl_ctrl_vfd_send_vfd *ids,
+				  struct virtio_wl_ctrl_vfd_send_vfd_v2 *ids_v2)
+{
+	size_t i;
+	int ret;
+	for (i = 0; i < vfd_count; i++) {
+		uint32_t kind = UINT_MAX;
+		uint32_t id = 0;
+		if (vfds[i]) {
+			kind = VIRTIO_WL_CTRL_VFD_SEND_KIND_LOCAL;
+			id = vfds[i]->id;
+		} else if (virtgpu_dma_bufs[i]) {
+			ret = get_dma_buf_id(virtgpu_dma_bufs[i],
+					     &id);
+			if (ret)
+				return ret;
+			kind = VIRTIO_WL_CTRL_VFD_SEND_KIND_VIRTGPU;
+		} else if (virtgpu_dma_fence[i]) {
+			ret = encode_fence(virtgpu_dma_fence[i],
+					   ids_v2 + i);
+			if (ret)
+				return ret;
+		} else {
+			return -EBADFD;
+		}
+		if (kind != UINT_MAX) {
+			if (ids) {
+				ids[i].kind = kind;
+				ids[i].id = cpu_to_le32(id);
+			} else {
+				ids_v2[i].kind = kind;
+				ids_v2[i].id = cpu_to_le32(id);
+			}
+		}
+	}
+	return 0;
+}
+#endif
+static int virtwl_vfd_send(struct file *filp, const char __user *buffer,
+					       u32 len, int *vfd_fds)
+{
+	struct virtwl_vfd *vfd = filp->private_data;
+	struct virtwl_info *vi = vfd->vi;
+	struct fd vfd_files[VIRTWL_SEND_MAX_ALLOCS] = { { 0 } };
+	struct virtwl_vfd *vfds[VIRTWL_SEND_MAX_ALLOCS] = { 0 };
+#ifdef SEND_VIRTGPU_RESOURCES
+	struct dma_buf *virtgpu_dma_bufs[VIRTWL_SEND_MAX_ALLOCS] = { 0 };
+	struct dma_fence *virtgpu_dma_fence[VIRTWL_SEND_MAX_ALLOCS] = { 0 };
+	bool foreign_id = false;
+#endif
+	size_t vfd_count = 0;
+	size_t vfd_ids_size;
+	size_t ctrl_send_size;
+	struct virtio_wl_ctrl_vfd_send *ctrl_send;
+	u8 *vfd_ids;
+	u8 *out_buffer;
+	struct completion finish_completion;
+	struct scatterlist out_sg;
+	struct scatterlist in_sg;
+	struct sg_table sgt;
+	struct vm_struct *area;
+	bool vmalloced;
+	int ret;
+	int i;
+	if (vfd_fds) {
+		for (i = 0; i < VIRTWL_SEND_MAX_ALLOCS; i++) {
+			struct fd vfd_file;
+			int fd = vfd_fds[i];
+			if (fd < 0)
+				break;
+			vfd_file = fdget(vfd_fds[i]);
+			if (!vfd_file.file) {
+				ret = -EBADFD;
+				goto put_files;
+			}
+			if (vfd_file.file->f_op == &virtwl_vfd_fops) {
+				vfd_files[i] = vfd_file;
+				vfds[i] = vfd_file.file->private_data;
+				if (vfds[i] && vfds[i]->id) {
+					vfd_count++;
+					continue;
+				}
+				ret = -EINVAL;
+				goto put_files;
+			} else {
+				struct dma_buf *dma_buf = ERR_PTR(-EINVAL);
+				struct dma_fence *dma_fence = ERR_PTR(-EINVAL);
+				bool handled = false;
+#ifdef SEND_VIRTGPU_RESOURCES
+				dma_buf = dma_buf_get(vfd_fds[i]);
+				dma_fence = vi->use_send_vfd_v2
+					? sync_file_get_fence(vfd_fds[i])
+					: ERR_PTR(-EINVAL);
+				handled = !IS_ERR(dma_buf) ||
+					  !IS_ERR(dma_fence);
+				if (!IS_ERR(dma_buf)) {
+					virtgpu_dma_bufs[i] = dma_buf;
+				} else {
+					virtgpu_dma_fence[i] = dma_fence;
+				}
+				foreign_id = true;
+				vfd_count++;
+#endif
+				fdput(vfd_file);
+				if (!handled) {
+					ret = IS_ERR(dma_buf) ?
+						PTR_ERR(dma_buf) :
+						PTR_ERR(dma_fence);
+					goto put_files;
+				}
+			}
+		}
+	}
+	/* Empty writes always succeed. */
+	if (len == 0 && vfd_count == 0)
+		return 0;
+	vfd_ids_size = vfd_count * sizeof(__le32);
+#ifdef SEND_VIRTGPU_RESOURCES
+	if (foreign_id) {
+		vfd_ids_size = vfd_count * (vi->use_send_vfd_v2
+			? sizeof(struct virtio_wl_ctrl_vfd_send_vfd_v2)
+			: sizeof(struct virtio_wl_ctrl_vfd_send_vfd));
+	}
+#endif
+	ctrl_send_size = sizeof(*ctrl_send) + vfd_ids_size + len;
+	vmalloced = false;
+	if (ctrl_send_size < PAGE_SIZE)
+		ctrl_send = kmalloc(ctrl_send_size, GFP_KERNEL);
+	else {
+		vmalloced = true;
+		ctrl_send = vmalloc(ctrl_send_size);
+	}
+	if (!ctrl_send) {
+		ret = -ENOMEM;
+		goto put_files;
+	}
+	vfd_ids = (u8 *)ctrl_send + sizeof(*ctrl_send);
+	out_buffer = (u8 *)ctrl_send + ctrl_send_size - len;
+	ctrl_send->hdr.type = VIRTIO_WL_CMD_VFD_SEND;
+	ctrl_send->hdr.flags = 0;
+#ifdef SEND_VIRTGPU_RESOURCES
+	if (foreign_id) {
+		struct virtio_wl_ctrl_vfd_send_vfd *v1 = NULL;
+		struct virtio_wl_ctrl_vfd_send_vfd_v2 *v2 = NULL;
+		if (vi->use_send_vfd_v2)
+			v2 = (struct virtio_wl_ctrl_vfd_send_vfd_v2 *) vfd_ids;
+		else
+			v1 = (struct virtio_wl_ctrl_vfd_send_vfd *) vfd_ids;
+		ctrl_send->hdr.type = VIRTIO_WL_CMD_VFD_SEND_FOREIGN_ID;
+		ret = encode_vfd_ids_foreign(vfds,
+			virtgpu_dma_bufs, virtgpu_dma_fence, vfd_count,
+			v1, v2);
+	} else {
+		ret = encode_vfd_ids(vfds, vfd_count, (__le32 *)vfd_ids);
+	}
+#else
+	ret = encode_vfd_ids(vfds, vfd_count, (__le32 *)vfd_ids);
+#endif
+	if (ret)
+		goto free_ctrl_send;
+	ctrl_send->vfd_id = vfd->id;
+	ctrl_send->vfd_count = vfd_count;
+	if (copy_from_user(out_buffer, buffer, len)) {
+		ret = -EFAULT;
+		goto free_ctrl_send;
+	}
+	init_completion(&finish_completion);
+	if (!vmalloced) {
+		sg_init_one(&out_sg, ctrl_send, ctrl_send_size);
+		sg_init_one(&in_sg, ctrl_send,
+		    sizeof(struct virtio_wl_ctrl_hdr));
+		ret = vq_queue_out(vi, &out_sg, &in_sg, &finish_completion,
+		    filp->f_flags & O_NONBLOCK);
+	} else {
+		#if 0  /* TODO */
+		area = find_vm_area(ctrl_send);
+		#endif
+		ret = sg_alloc_table_from_pages(&sgt, area->pages,
+		    area->nr_pages, 0, ctrl_send_size, GFP_KERNEL);
+		if (ret)
+			goto free_ctrl_send;
+		sg_init_table(&in_sg, 1);
+		sg_set_page(&in_sg, area->pages[0],
+		    sizeof(struct virtio_wl_ctrl_hdr), 0);
+		ret = vq_queue_out(vi, sgt.sgl, &in_sg, &finish_completion,
+		    filp->f_flags & O_NONBLOCK);
+	}
+	if (ret)
+		goto free_sgt;
+	wait_for_completion(&finish_completion);
+	ret = virtwl_resp_err(ctrl_send->hdr.type);
+free_sgt:
+	if (vmalloced)
+		sg_free_table(&sgt);
+free_ctrl_send:
+	kvfree(ctrl_send);
+put_files:
+	for (i = 0; i < VIRTWL_SEND_MAX_ALLOCS; i++) {
+		if (vfd_files[i].file)
+			fdput(vfd_files[i]);
+#ifdef SEND_VIRTGPU_RESOURCES
+		if (virtgpu_dma_bufs[i])
+			dma_buf_put(virtgpu_dma_bufs[i]);
+		if (virtgpu_dma_fence[i])
+			dma_fence_put(virtgpu_dma_fence[i]);
+#endif
+	}
+	return ret;
+}
+static int virtwl_vfd_dmabuf_sync(struct file *filp, u32 flags)
+{
+	struct virtio_wl_ctrl_vfd_dmabuf_sync *ctrl_dmabuf_sync;
+	struct virtwl_vfd *vfd = filp->private_data;
+	struct virtwl_info *vi = vfd->vi;
+	struct completion finish_completion;
+	struct scatterlist out_sg;
+	struct scatterlist in_sg;
+	int ret = 0;
+	ctrl_dmabuf_sync = kzalloc(sizeof(*ctrl_dmabuf_sync), GFP_KERNEL);
+	if (!ctrl_dmabuf_sync)
+		return -ENOMEM;
+	ctrl_dmabuf_sync->hdr.type = VIRTIO_WL_CMD_VFD_DMABUF_SYNC;
+	ctrl_dmabuf_sync->vfd_id = vfd->id;
+	ctrl_dmabuf_sync->flags = flags;
+	sg_init_one(&out_sg, &ctrl_dmabuf_sync->hdr,
+		    sizeof(struct virtio_wl_ctrl_vfd_dmabuf_sync));
+	sg_init_one(&in_sg, &ctrl_dmabuf_sync->hdr,
+		    sizeof(struct virtio_wl_ctrl_hdr));
+	init_completion(&finish_completion);
+	ret = vq_queue_out(vi, &out_sg, &in_sg, &finish_completion,
+			   false /* block */);
+	if (ret) {
+		pr_warn("virtwl: failed to queue dmabuf sync vfd id %u: %d\n",
+			vfd->id,
+			ret);
+		goto free_ctrl_dmabuf_sync;
+	}
+	wait_for_completion(&finish_completion);
+free_ctrl_dmabuf_sync:
+	kfree(ctrl_dmabuf_sync);
+	return ret;
+}
+static ssize_t virtwl_vfd_read(struct file *filp, char __user *buffer,
+			       size_t size, loff_t *pos)
+{
+	return virtwl_vfd_recv(filp, buffer, size, NULL, NULL);
+}
+static ssize_t virtwl_vfd_write(struct file *filp, const char __user *buffer,
+				size_t size, loff_t *pos)
+{
+	int ret = 0;
+	if (size > U32_MAX)
+		size = U32_MAX;
+	ret = virtwl_vfd_send(filp, buffer, size, NULL);
+	if (ret)
+		return ret;
+	return size;
+}
+static int virtwl_vfd_mmap(struct file *filp, struct vm_area_struct *vma)
+{
+	struct virtwl_vfd *vfd = filp->private_data;
+	unsigned long vm_size = vma->vm_end - vma->vm_start;
+	int ret = 0;
+	mutex_lock(&vfd->lock);
+	if (!vfd->pfn) {
+		ret = -EACCES;
+		goto out_unlock;
+	}
+	if (vm_size + (vma->vm_pgoff << PAGE_SHIFT) > PAGE_ALIGN(vfd->size)) {
+		ret = -EINVAL;
+		goto out_unlock;
+	}
+	ret = io_remap_pfn_range(vma, vma->vm_start, vfd->pfn, vm_size,
+				 vma->vm_page_prot);
+	if (ret)
+		goto out_unlock;
+#if 0
+	vma->vm_flags |= VM_PFNMAP | VM_IO | VM_DONTEXPAND | VM_DONTDUMP;
+#endif
+
+out_unlock:
+	mutex_unlock(&vfd->lock);
+	return ret;
+}
+static unsigned int virtwl_vfd_poll(struct file *filp,
+				    struct poll_table_struct *wait)
+{
+	struct virtwl_vfd *vfd = filp->private_data;
+	struct virtwl_info *vi = vfd->vi;
+	unsigned int mask = 0;
+	mutex_lock(&vi->vq_locks[VIRTWL_VQ_OUT]);
+	poll_wait(filp, &vi->out_waitq, wait);
+	if (vi->vqs[VIRTWL_VQ_OUT]->num_free)
+		mask |= POLLOUT | POLLWRNORM;
+	mutex_unlock(&vi->vq_locks[VIRTWL_VQ_OUT]);
+	mutex_lock(&vfd->lock);
+	poll_wait(filp, &vfd->in_waitq, wait);
+	if (!list_empty(&vfd->in_queue))
+		mask |= POLLIN | POLLRDNORM;
+	if (vfd->hungup)
+		mask |= POLLHUP;
+	mutex_unlock(&vfd->lock);
+	return mask;
+}
+static int virtwl_vfd_release(struct inode *inodep, struct file *filp)
+{
+	struct virtwl_vfd *vfd = filp->private_data;
+	uint32_t vfd_id = vfd->id;
+	int ret;
+	/*
+	 * If release is called, filp must be out of references and we have the
+	 * last reference.
+	 */
+	ret = do_vfd_close(vfd);
+	if (ret)
+		pr_warn("virtwl: failed to release vfd id %u: %d\n", vfd_id,
+			ret);
+	return 0;
+}
+static int virtwl_open(struct inode *inodep, struct file *filp)
+{
+	struct virtwl_info *vi = container_of(inodep->i_cdev,
+					      struct virtwl_info, cdev);
+	filp->private_data = vi;
+	return 0;
+}
+static struct virtwl_vfd *do_new(struct virtwl_info *vi,
+				 struct virtwl_ioctl_new *ioctl_new,
+				 size_t ioctl_new_size, bool nonblock)
+{
+	struct virtio_wl_ctrl_vfd_new *ctrl_new;
+	struct virtwl_vfd *vfd;
+	struct completion finish_completion;
+	struct scatterlist out_sg;
+	struct scatterlist in_sg;
+	int ret = 0;
+	if (ioctl_new->type != VIRTWL_IOCTL_NEW_CTX &&
+		ioctl_new->type != VIRTWL_IOCTL_NEW_CTX_NAMED &&
+		ioctl_new->type != VIRTWL_IOCTL_NEW_ALLOC &&
+		ioctl_new->type != VIRTWL_IOCTL_NEW_PIPE_READ &&
+		ioctl_new->type != VIRTWL_IOCTL_NEW_PIPE_WRITE &&
+		ioctl_new->type != VIRTWL_IOCTL_NEW_DMABUF)
+		return ERR_PTR(-EINVAL);
+	ctrl_new = kzalloc(sizeof(*ctrl_new), GFP_KERNEL);
+	if (!ctrl_new)
+		return ERR_PTR(-ENOMEM);
+	vfd = virtwl_vfd_alloc(vi);
+	if (!vfd) {
+		ret = -ENOMEM;
+		goto free_ctrl_new;
+	}
+	mutex_lock(&vi->vfds_lock);
+	/*
+	 * Take the lock before adding it to the vfds list where others might
+	 * reference it.
+	 */
+	mutex_lock(&vfd->lock);
+	ret = idr_alloc(&vi->vfds, vfd, 1, VIRTWL_MAX_ALLOC, GFP_KERNEL);
+	mutex_unlock(&vi->vfds_lock);
+	if (ret <= 0)
+		goto remove_vfd;
+	vfd->id = ret;
+	ret = 0;
+	ctrl_new->vfd_id = vfd->id;
+	switch (ioctl_new->type) {
+	case VIRTWL_IOCTL_NEW_CTX:
+		ctrl_new->hdr.type = VIRTIO_WL_CMD_VFD_NEW_CTX;
+		ctrl_new->flags = VIRTIO_WL_VFD_WRITE | VIRTIO_WL_VFD_READ;
+		break;
+	case VIRTWL_IOCTL_NEW_CTX_NAMED:
+		ctrl_new->hdr.type = VIRTIO_WL_CMD_VFD_NEW_CTX_NAMED;
+		ctrl_new->flags = VIRTIO_WL_VFD_WRITE | VIRTIO_WL_VFD_READ;
+		memcpy(ctrl_new->name, ioctl_new->name, sizeof(ctrl_new->name));
+		break;
+	case VIRTWL_IOCTL_NEW_ALLOC:
+		ctrl_new->hdr.type = VIRTIO_WL_CMD_VFD_NEW;
+		ctrl_new->size = PAGE_ALIGN(ioctl_new->size);
+		break;
+	case VIRTWL_IOCTL_NEW_PIPE_READ:
+		ctrl_new->hdr.type = VIRTIO_WL_CMD_VFD_NEW_PIPE;
+		ctrl_new->flags = VIRTIO_WL_VFD_READ;
+		break;
+	case VIRTWL_IOCTL_NEW_PIPE_WRITE:
+		ctrl_new->hdr.type = VIRTIO_WL_CMD_VFD_NEW_PIPE;
+		ctrl_new->flags = VIRTIO_WL_VFD_WRITE;
+		break;
+	case VIRTWL_IOCTL_NEW_DMABUF:
+		/* Make sure ioctl_new contains enough data for NEW_DMABUF. */
+		if (ioctl_new_size == sizeof(*ioctl_new)) {
+			ctrl_new->hdr.type = VIRTIO_WL_CMD_VFD_NEW_DMABUF;
+			/* FIXME: convert from host byte order. */
+			memcpy(&ctrl_new->dmabuf, &ioctl_new->dmabuf,
+			       sizeof(ioctl_new->dmabuf));
+			break;
+		}
+		fallthrough;
+	default:
+		ret = -EINVAL;
+		goto remove_vfd;
+	}
+	init_completion(&finish_completion);
+	sg_init_one(&out_sg, ctrl_new, sizeof(*ctrl_new));
+	sg_init_one(&in_sg, ctrl_new, sizeof(*ctrl_new));
+	ret = vq_queue_out(vi, &out_sg, &in_sg, &finish_completion, nonblock);
+	if (ret)
+		goto remove_vfd;
+	wait_for_completion(&finish_completion);
+	ret = virtwl_resp_err(ctrl_new->hdr.type);
+	if (ret)
+		goto remove_vfd;
+	vfd->size = ctrl_new->size;
+	vfd->pfn = decode_pfn(vi, ctrl_new);
+	vfd->flags = ctrl_new->flags;
+	mutex_unlock(&vfd->lock);
+	if (ioctl_new->type == VIRTWL_IOCTL_NEW_DMABUF) {
+		/* FIXME: convert to host byte order. */
+		memcpy(&ioctl_new->dmabuf, &ctrl_new->dmabuf,
+		       sizeof(ctrl_new->dmabuf));
+	}
+	kfree(ctrl_new);
+	return vfd;
+remove_vfd:
+	/*
+	 * unlock the vfd to avoid deadlock when unlinking it
+	 * or freeing a held lock
+	 */
+	mutex_unlock(&vfd->lock);
+	/* this is safe since the id cannot change after the vfd is created */
+	if (vfd->id)
+		virtwl_vfd_lock_unlink(vfd);
+	virtwl_vfd_free(vfd);
+free_ctrl_new:
+	kfree(ctrl_new);
+	return ERR_PTR(ret);
+}
+static long virtwl_ioctl_send(struct file *filp, void __user *ptr)
+{
+	struct virtwl_ioctl_txn ioctl_send;
+	void __user *user_data = ptr + sizeof(struct virtwl_ioctl_txn);
+	int ret;
+	ret = copy_from_user(&ioctl_send, ptr, sizeof(struct virtwl_ioctl_txn));
+	if (ret)
+		return -EFAULT;
+	/* Early check for user error; do_send still uses copy_from_user. */
+	ret = !access_ok(user_data, ioctl_send.len);
+	if (ret)
+		return -EFAULT;
+	return virtwl_vfd_send(filp, user_data, ioctl_send.len, ioctl_send.fds);
+}
+static long virtwl_ioctl_recv(struct file *filp, void __user *ptr)
+{
+	struct virtwl_ioctl_txn ioctl_recv;
+	void __user *user_data = ptr + sizeof(struct virtwl_ioctl_txn);
+	int __user *user_fds = (int __user *)ptr;
+	size_t vfd_count = VIRTWL_SEND_MAX_ALLOCS;
+	struct virtwl_vfd *vfds[VIRTWL_SEND_MAX_ALLOCS] = { 0 };
+	int fds[VIRTWL_SEND_MAX_ALLOCS];
+	size_t i;
+	int ret = 0;
+	for (i = 0; i < VIRTWL_SEND_MAX_ALLOCS; i++)
+		fds[i] = -1;
+	ret = copy_from_user(&ioctl_recv, ptr, sizeof(struct virtwl_ioctl_txn));
+	if (ret)
+		return -EFAULT;
+	/* Early check for user error. */
+	ret = !access_ok(user_data, ioctl_recv.len);
+	if (ret)
+		return -EFAULT;
+	ret = virtwl_vfd_recv(filp, user_data, ioctl_recv.len, vfds,
+			      &vfd_count);
+	if (ret < 0)
+		return ret;
+	ret = copy_to_user(&((struct virtwl_ioctl_txn __user *)ptr)->len, &ret,
+			   sizeof(ioctl_recv.len));
+	if (ret) {
+		ret = -EFAULT;
+		goto free_vfds;
+	}
+	for (i = 0; i < vfd_count; i++) {
+		ret = anon_inode_getfd("[virtwl_vfd]", &virtwl_vfd_fops,
+				       vfds[i], virtwl_vfd_file_flags(vfds[i])
+				       | O_CLOEXEC);
+		if (ret < 0)
+			goto free_vfds;
+		vfds[i] = NULL;
+		fds[i] = ret;
+	}
+	ret = copy_to_user(user_fds, fds, sizeof(int) * VIRTWL_SEND_MAX_ALLOCS);
+	if (ret) {
+		ret = -EFAULT;
+		goto free_vfds;
+	}
+	return 0;
+free_vfds:
+	for (i = 0; i < vfd_count; i++) {
+		if (vfds[i])
+			do_vfd_close(vfds[i]);
+		if (fds[i] >= 0)
+			__close_fd(current->files, fds[i]);
+	}
+	return ret;
+}
+static long virtwl_ioctl_dmabuf_sync(struct file *filp, void __user *ptr)
+{
+	struct virtwl_ioctl_dmabuf_sync ioctl_dmabuf_sync;
+	int ret;
+	ret = copy_from_user(&ioctl_dmabuf_sync, ptr,
+			     sizeof(struct virtwl_ioctl_dmabuf_sync));
+	if (ret)
+		return -EFAULT;
+	if (ioctl_dmabuf_sync.flags & ~DMA_BUF_SYNC_VALID_FLAGS_MASK)
+		return -EINVAL;
+	return virtwl_vfd_dmabuf_sync(filp, ioctl_dmabuf_sync.flags);
+}
+static long virtwl_vfd_ioctl(struct file *filp, unsigned int cmd,
+			     void __user *ptr)
+{
+	switch (cmd) {
+	case VIRTWL_IOCTL_SEND:
+		return virtwl_ioctl_send(filp, ptr);
+	case VIRTWL_IOCTL_RECV:
+		return virtwl_ioctl_recv(filp, ptr);
+	case VIRTWL_IOCTL_DMABUF_SYNC:
+		return virtwl_ioctl_dmabuf_sync(filp, ptr);
+	default:
+		return -ENOTTY;
+	}
+}
+static long virtwl_ioctl_new(struct file *filp, void __user *ptr,
+			     size_t in_size)
+{
+	struct virtwl_info *vi = filp->private_data;
+	struct virtwl_vfd *vfd;
+	struct virtwl_ioctl_new ioctl_new = {};
+	size_t size = min(in_size, sizeof(ioctl_new));
+	int ret;
+	/* Early check for user error. */
+	ret = !access_ok(ptr, size);
+	if (ret)
+		return -EFAULT;
+	ret = copy_from_user(&ioctl_new, ptr, size);
+	if (ret)
+		return -EFAULT;
+	vfd = do_new(vi, &ioctl_new, size, filp->f_flags & O_NONBLOCK);
+	if (IS_ERR(vfd))
+		return PTR_ERR(vfd);
+	ret = anon_inode_getfd("[virtwl_vfd]", &virtwl_vfd_fops, vfd,
+			       virtwl_vfd_file_flags(vfd) | O_CLOEXEC);
+	if (ret < 0) {
+		do_vfd_close(vfd);
+		return ret;
+	}
+	ioctl_new.fd = ret;
+	ret = copy_to_user(ptr, &ioctl_new, size);
+	if (ret) {
+		/* The release operation will handle freeing this alloc */
+		ksys_close(ioctl_new.fd);
+		return -EFAULT;
+	}
+	return 0;
+}
+static long virtwl_ioctl_ptr(struct file *filp, unsigned int cmd,
+			     void __user *ptr)
+{
+	if (filp->f_op == &virtwl_vfd_fops)
+		return virtwl_vfd_ioctl(filp, cmd, ptr);
+	switch (_IOC_NR(cmd)) {
+	case _IOC_NR(VIRTWL_IOCTL_NEW):
+		return virtwl_ioctl_new(filp, ptr, _IOC_SIZE(cmd));
+	default:
+		return -ENOTTY;
+	}
+}
+static long virtwl_ioctl(struct file *filp, unsigned int cmd, unsigned long arg)
+{
+	return virtwl_ioctl_ptr(filp, cmd, (void __user *)arg);
+}
+#ifdef CONFIG_COMPAT
+static long virtwl_ioctl_compat(struct file *filp, unsigned int cmd,
+				unsigned long arg)
+{
+	return virtwl_ioctl_ptr(filp, cmd, compat_ptr(arg));
+}
+#else
+#define virtwl_ioctl_compat NULL
+#endif
+static int virtwl_release(struct inode *inodep, struct file *filp)
+{
+	return 0;
+}
+static const struct file_operations virtwl_fops = {
+	.open = virtwl_open,
+	.unlocked_ioctl = virtwl_ioctl,
+	.compat_ioctl = virtwl_ioctl_compat,
+	.release = virtwl_release,
+};
+static const struct file_operations virtwl_vfd_fops = {
+	.read = virtwl_vfd_read,
+	.write = virtwl_vfd_write,
+	.mmap = virtwl_vfd_mmap,
+	.poll = virtwl_vfd_poll,
+	.unlocked_ioctl = virtwl_ioctl,
+	.compat_ioctl = virtwl_ioctl_compat,
+	.release = virtwl_vfd_release,
+};
+static int probe_common(struct virtio_device *vdev)
+{
+	int i;
+	int ret;
+	struct virtwl_info *vi = NULL;
+	vq_callback_t *vq_callbacks[] = { vq_in_cb, vq_out_cb };
+	static const char * const vq_names[] = { "in", "out" };
+	vi = kzalloc(sizeof(struct virtwl_info), GFP_KERNEL);
+	if (!vi)
+		return -ENOMEM;
+	vdev->priv = vi;
+	ret = alloc_chrdev_region(&vi->dev_num, 0, 1, "wl");
+	if (ret) {
+		ret = -ENOMEM;
+		pr_warn("virtwl: failed to allocate wl chrdev region: %d\n",
+			ret);
+		goto free_vi;
+	}
+	vi->class = class_create(THIS_MODULE, "wl");
+	if (IS_ERR(vi->class)) {
+		ret = PTR_ERR(vi->class);
+		pr_warn("virtwl: failed to create wl class: %d\n", ret);
+		goto unregister_region;
+	}
+	vi->dev = device_create(vi->class, NULL, vi->dev_num, vi, "wl%d", 0);
+	if (IS_ERR(vi->dev)) {
+		ret = PTR_ERR(vi->dev);
+		pr_warn("virtwl: failed to create wl0 device: %d\n", ret);
+		goto destroy_class;
+	}
+	cdev_init(&vi->cdev, &virtwl_fops);
+	ret = cdev_add(&vi->cdev, vi->dev_num, 1);
+	if (ret) {
+		pr_warn("virtwl: failed to add virtio wayland character device to system: %d\n",
+			ret);
+		goto destroy_device;
+	}
+	for (i = 0; i < VIRTWL_QUEUE_COUNT; i++)
+		mutex_init(&vi->vq_locks[i]);
+	ret = virtio_find_vqs(vdev, VIRTWL_QUEUE_COUNT, vi->vqs, vq_callbacks,
+			      vq_names, NULL);
+	if (ret) {
+		pr_warn("virtwl: failed to find virtio wayland queues: %d\n",
+			ret);
+		goto del_cdev;
+	}
+	INIT_WORK(&vi->in_vq_work, vq_in_work_handler);
+	INIT_WORK(&vi->out_vq_work, vq_out_work_handler);
+	init_waitqueue_head(&vi->out_waitq);
+	mutex_init(&vi->vfds_lock);
+	idr_init(&vi->vfds);
+	vi->use_send_vfd_v2 = virtio_has_feature(vdev, VIRTIO_WL_F_SEND_FENCES);
+	if (virtio_has_feature(vdev, VIRTIO_WL_F_USE_SHMEM)) {
+		struct virtio_shm_region region;
+		if (!virtio_get_shm_region(vdev, &region, 0)) {
+			pr_warn("virtwl: failed to find shm region");
+			goto del_cdev;
+		}
+		vi->pfn_base = region.addr >> PAGE_SHIFT;
+		vi->invalid_pfn = region.len >> PAGE_SHIFT;
+	}
+	/* lock is unneeded as we have unique ownership */
+	ret = vq_fill_locked(vi->vqs[VIRTWL_VQ_IN]);
+	if (ret) {
+		pr_warn("virtwl: failed to fill in virtqueue: %d", ret);
+		goto del_cdev;
+	}
+	virtio_device_ready(vdev);
+	virtqueue_kick(vi->vqs[VIRTWL_VQ_IN]);
+	return 0;
+del_cdev:
+	cdev_del(&vi->cdev);
+destroy_device:
+	put_device(vi->dev);
+destroy_class:
+	class_destroy(vi->class);
+unregister_region:
+	unregister_chrdev_region(vi->dev_num, 0);
+free_vi:
+	kfree(vi);
+	return ret;
+}
+static void remove_common(struct virtio_device *vdev)
+{
+	struct virtwl_info *vi = vdev->priv;
+	cdev_del(&vi->cdev);
+	put_device(vi->dev);
+	class_destroy(vi->class);
+	unregister_chrdev_region(vi->dev_num, 0);
+	kfree(vi);
+}
+static int virtwl_probe(struct virtio_device *vdev)
+{
+	return probe_common(vdev);
+}
+static void virtwl_remove(struct virtio_device *vdev)
+{
+	remove_common(vdev);
+}
+static void virtwl_scan(struct virtio_device *vdev)
+{
+}
+static struct virtio_device_id id_table[] = {
+	{ VIRTIO_ID_WL, VIRTIO_DEV_ANY_ID },
+	{ 0 },
+};
+static unsigned int features_legacy[] = {
+	VIRTIO_WL_F_TRANS_FLAGS
+};
+static unsigned int features[] = {
+	VIRTIO_WL_F_TRANS_FLAGS,
+	VIRTIO_WL_F_SEND_FENCES,
+	VIRTIO_WL_F_USE_SHMEM,
+};
+static struct virtio_driver virtio_wl_driver = {
+	.driver.name =	KBUILD_MODNAME,
+	.driver.owner =	THIS_MODULE,
+	.id_table =	id_table,
+	.feature_table = features,
+	.feature_table_size = ARRAY_SIZE(features),
+	.feature_table_legacy = features_legacy,
+	.feature_table_size_legacy = ARRAY_SIZE(features_legacy),
+	.probe =	virtwl_probe,
+	.remove =	virtwl_remove,
+	.scan =		virtwl_scan,
+};
+module_virtio_driver(virtio_wl_driver);
+MODULE_DEVICE_TABLE(virtio, id_table);
+MODULE_DESCRIPTION("Virtio wayland driver");
+MODULE_LICENSE("GPL");
diff --git a/drivers/virtio/virtio_wl.h b/drivers/virtio/virtio_wl.h
new file mode 100644
index 000000000000..f28e8a5644e1
--- /dev/null
+++ b/drivers/virtio/virtio_wl.h
@@ -0,0 +1,154 @@
+#ifndef _LINUX_VIRTIO_WL_H
+#define _LINUX_VIRTIO_WL_H
+/*
+ * This header is BSD licensed so anyone can use the definitions to implement
+ * compatible drivers/servers.
+ */
+#include <linux/virtio_ids.h>
+#include <linux/virtio_config.h>
+#include "virtwl.h"
+
+#define VIRTWL_IN_BUFFER_SIZE 4096
+#define VIRTWL_OUT_BUFFER_SIZE 4096
+#define VIRTWL_VQ_IN 0
+#define VIRTWL_VQ_OUT 1
+#define VIRTWL_QUEUE_COUNT 2
+#define VIRTWL_MAX_ALLOC 0x800
+#define VIRTWL_PFN_SHIFT 12
+
+/* Enables the transition to new flag semantics */
+#define VIRTIO_WL_F_TRANS_FLAGS 1
+/* Enables send fence support with virtio_wl_ctrl_vfd_send_vfd_v2 */
+#define VIRTIO_WL_F_SEND_FENCES 2
+
+struct virtio_wl_config {
+};
+
+/*
+ * The structure of each of these is virtio_wl_ctrl_hdr or one of its subclasses
+ * where noted.
+ */
+enum virtio_wl_ctrl_type {
+	VIRTIO_WL_CMD_VFD_NEW = 0x100, /* virtio_wl_ctrl_vfd_new */
+	VIRTIO_WL_CMD_VFD_CLOSE, /* virtio_wl_ctrl_vfd */
+	VIRTIO_WL_CMD_VFD_SEND, /* virtio_wl_ctrl_vfd_send + data */
+	VIRTIO_WL_CMD_VFD_RECV, /* virtio_wl_ctrl_vfd_recv + data */
+	VIRTIO_WL_CMD_VFD_NEW_CTX, /* virtio_wl_ctrl_vfd_new */
+	VIRTIO_WL_CMD_VFD_NEW_PIPE, /* virtio_wl_ctrl_vfd_new */
+	VIRTIO_WL_CMD_VFD_HUP, /* virtio_wl_ctrl_vfd */
+	VIRTIO_WL_CMD_VFD_NEW_DMABUF, /* virtio_wl_ctrl_vfd_new */
+	VIRTIO_WL_CMD_VFD_DMABUF_SYNC, /* virtio_wl_ctrl_vfd_dmabuf_sync */
+	VIRTIO_WL_CMD_VFD_SEND_FOREIGN_ID, /* virtio_wl_ctrl_vfd_send + data */
+	VIRTIO_WL_CMD_VFD_NEW_CTX_NAMED, /* virtio_wl_ctrl_vfd_new */
+
+	VIRTIO_WL_RESP_OK = 0x1000,
+	VIRTIO_WL_RESP_VFD_NEW = 0x1001, /* virtio_wl_ctrl_vfd_new */
+	VIRTIO_WL_RESP_VFD_NEW_DMABUF = 0x1002, /* virtio_wl_ctrl_vfd_new */
+
+	VIRTIO_WL_RESP_ERR = 0x1100,
+	VIRTIO_WL_RESP_OUT_OF_MEMORY,
+	VIRTIO_WL_RESP_INVALID_ID,
+	VIRTIO_WL_RESP_INVALID_TYPE,
+	VIRTIO_WL_RESP_INVALID_FLAGS,
+	VIRTIO_WL_RESP_INVALID_CMD,
+};
+
+struct virtio_wl_ctrl_hdr {
+	__le32 type; /* one of virtio_wl_ctrl_type */
+	__le32 flags; /* always 0 */
+};
+
+enum virtio_wl_vfd_flags {
+	VIRTIO_WL_VFD_WRITE = 0x1, /* intended to be written by guest */
+	VIRTIO_WL_VFD_READ = 0x2, /* intended to be read by guest */
+};
+
+struct virtio_wl_ctrl_vfd {
+	struct virtio_wl_ctrl_hdr hdr;
+	__le32 vfd_id;
+};
+
+/*
+ * If this command is sent to the guest, it indicates that the VFD has been
+ * created and the fields indicate the properties of the VFD being offered.
+ *
+ * If this command is sent to the host, it represents a request to create a VFD
+ * of the given properties. The pfn field is ignored by the host.
+ */
+struct virtio_wl_ctrl_vfd_new {
+	struct virtio_wl_ctrl_hdr hdr;
+	__le32 vfd_id; /* MSB indicates device allocated vfd */
+	__le32 flags; /* virtio_wl_vfd_flags */
+	__le64 pfn; /* first guest physical page frame number if VFD_MAP */
+	__le32 size; /* size in bytes if VIRTIO_WL_CMD_VFD_NEW* */
+	union {
+		/* buffer description if VIRTIO_WL_CMD_VFD_NEW_DMABUF */
+		struct {
+			__le32 width; /* width in pixels */
+			__le32 height; /* height in pixels */
+			__le32 format; /* fourcc format */
+			__le32 stride0; /* return stride0 */
+			__le32 stride1; /* return stride1 */
+			__le32 stride2; /* return stride2 */
+			__le32 offset0; /* return offset0 */
+			__le32 offset1; /* return offset1 */
+			__le32 offset2; /* return offset2 */
+		} dmabuf;
+		/* name of socket if VIRTIO_WL_CMD_VFD_NEW_CTX_NAMED */
+		char name[32];
+	};
+};
+
+
+enum virtio_wl_ctrl_vfd_send_kind {
+	/* The id after this one indicates an ordinary vfd_id. */
+	VIRTIO_WL_CTRL_VFD_SEND_KIND_LOCAL,
+	/* The id after this one is a virtio-gpu resource id. */
+	VIRTIO_WL_CTRL_VFD_SEND_KIND_VIRTGPU,
+	VIRTIO_WL_CTRL_VFD_SEND_KIND_VIRTGPU_FENCE,
+	VIRTIO_WL_CTRL_VFD_SEND_KIND_VIRTGPU_SIGNALED_FENCE,
+};
+
+struct virtio_wl_ctrl_vfd_send_vfd {
+	__le32 kind; /* virtio_wl_ctrl_vfd_send_kind */
+	__le32 id;
+};
+
+struct virtio_wl_ctrl_vfd_send_vfd_v2 {
+	__le32 kind; /* virtio_wl_ctrl_vfd_send_kind */
+	union {
+		/* For KIND_LOCAL and KIND_VIRTGPU */
+		__le32 id;
+		/* For KIND_VIRTGPU_FENCE */
+		__le64 seqno;
+	};
+};
+
+struct virtio_wl_ctrl_vfd_send {
+	struct virtio_wl_ctrl_hdr hdr;
+	__le32 vfd_id;
+	__le32 vfd_count; /* struct is followed by this many IDs */
+
+	/*
+	 * If hdr.type == VIRTIO_WL_CMD_VFD_SEND_FOREIGN_ID, there is a
+	 * vfd_count array of virtio_wl_ctrl_vfd_send_vfd. Otherwise, there is a
+	 * vfd_count array of vfd_ids.
+	 */
+
+	/* the remainder is raw data */
+};
+
+struct virtio_wl_ctrl_vfd_recv {
+	struct virtio_wl_ctrl_hdr hdr;
+	__le32 vfd_id;
+	__le32 vfd_count; /* struct is followed by this many IDs */
+	/* the remainder is raw data */
+};
+
+struct virtio_wl_ctrl_vfd_dmabuf_sync {
+	struct virtio_wl_ctrl_hdr hdr;
+	__le32 vfd_id;
+	__le32 flags;
+};
+
+#endif /* _LINUX_VIRTIO_WL_H */
diff --git a/drivers/virtio/virtwl.h b/drivers/virtio/virtwl.h
new file mode 100644
index 000000000000..4afbcfe5cb5d
--- /dev/null
+++ b/drivers/virtio/virtwl.h
@@ -0,0 +1,69 @@
+#ifndef _LINUX_VIRTWL_H
+#define _LINUX_VIRTWL_H
+
+#include <asm/ioctl.h>
+#include <linux/types.h>
+
+#define VIRTIO_ID_WL           63 /* virtio wayland */
+
+#define VIRTWL_SEND_MAX_ALLOCS 28
+
+#define VIRTWL_IOCTL_BASE 'w'
+#define VIRTWL_IO(nr)		_IO(VIRTWL_IOCTL_BASE, nr)
+#define VIRTWL_IOR(nr, type)	_IOR(VIRTWL_IOCTL_BASE, nr, type)
+#define VIRTWL_IOW(nr, type)	_IOW(VIRTWL_IOCTL_BASE, nr, type)
+#define VIRTWL_IOWR(nr, type)	_IOWR(VIRTWL_IOCTL_BASE, nr, type)
+
+enum virtwl_ioctl_new_type {
+	VIRTWL_IOCTL_NEW_CTX, /* open a new wayland connection context */
+	VIRTWL_IOCTL_NEW_ALLOC, /* create a new virtwl shm allocation */
+	/* create a new virtwl pipe that is readable via the returned fd */
+	VIRTWL_IOCTL_NEW_PIPE_READ,
+	/* create a new virtwl pipe that is writable via the returned fd */
+	VIRTWL_IOCTL_NEW_PIPE_WRITE,
+	/* create a new virtwl dmabuf that is writable via the returned fd */
+	VIRTWL_IOCTL_NEW_DMABUF,
+	VIRTWL_IOCTL_NEW_CTX_NAMED, /* open a new named connection context */
+};
+
+struct virtwl_ioctl_new {
+	__u32 type; /* VIRTWL_IOCTL_NEW_* */
+	int fd; /* return fd */
+	__u32 flags; /* currently always 0 */
+	union {
+		/* size of allocation if type == VIRTWL_IOCTL_NEW_ALLOC */
+		__u32 size;
+		/* buffer description if type == VIRTWL_IOCTL_NEW_DMABUF */
+		struct {
+			__u32 width; /* width in pixels */
+			__u32 height; /* height in pixels */
+			__u32 format; /* fourcc format */
+			__u32 stride0; /* return stride0 */
+			__u32 stride1; /* return stride1 */
+			__u32 stride2; /* return stride2 */
+			__u32 offset0; /* return offset0 */
+			__u32 offset1; /* return offset1 */
+			__u32 offset2; /* return offset2 */
+		} dmabuf;
+		/* name of socket if type == VIRTIO_WL_CMD_VFD_NEW_CTX_NAMED */
+		char name[32];
+	};
+};
+
+struct virtwl_ioctl_txn {
+	int fds[VIRTWL_SEND_MAX_ALLOCS];
+	__u32 len;
+	__u8 data[0];
+};
+
+struct virtwl_ioctl_dmabuf_sync {
+	__u32 flags; /* synchronization flags (see dma-buf.h) */
+};
+
+#define VIRTWL_IOCTL_NEW VIRTWL_IOWR(0x00, struct virtwl_ioctl_new)
+#define VIRTWL_IOCTL_SEND VIRTWL_IOR(0x01, struct virtwl_ioctl_txn)
+#define VIRTWL_IOCTL_RECV VIRTWL_IOW(0x02, struct virtwl_ioctl_txn)
+#define VIRTWL_IOCTL_DMABUF_SYNC VIRTWL_IOR(0x03, \
+					    struct virtwl_ioctl_dmabuf_sync)
+
+#endif /* _LINUX_VIRTWL_H */
-- 
2.40.1

